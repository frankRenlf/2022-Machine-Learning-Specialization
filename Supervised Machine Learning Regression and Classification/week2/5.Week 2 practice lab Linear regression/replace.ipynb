{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 569\u001B[0m\n\u001B[0;32m      1\u001B[0m {\n\u001B[0;32m      2\u001B[0m  \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcells\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m      3\u001B[0m   {\n\u001B[0;32m      4\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      5\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m      6\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Practice Lab: Linear Regression\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWelcome to your first practice lab! In this lab, you will implement linear regression with one variable to predict profits for a restaurant franchise.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Outline\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- [ 1 - Packages ](#1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- [ 2 - Linear regression with one variable ](#2)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  - [ 2.1 Problem Statement](#2.1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  - [ 2.2  Dataset](#2.2)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  - [ 2.3 Refresher on linear regression](#2.3)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  - [ 2.4  Compute Cost](#2.4)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    - [ Exercise 1](#ex01)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  - [ 2.5 Gradient descent ](#2.5)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    - [ Exercise 2](#ex02)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  - [ 2.6 Learning parameters using batch gradient descent ](#2.6)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     23\u001B[0m    ]\n\u001B[0;32m     24\u001B[0m   },\n\u001B[0;32m     25\u001B[0m   {\n\u001B[0;32m     26\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     27\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m     28\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<a name=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m1\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m></a>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m## 1 - Packages \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFirst, let\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms run the cell below to import all the packages that you will need during this assignment.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- [numpy](www.numpy.org) is the fundamental package for working with matrices in Python.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- [matplotlib](http://matplotlib.org) is a famous library to plot graphs in Python.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     35\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- ``utils.py`` contains helper functions for this assignment. You do not need to modify code in this file.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     36\u001B[0m    ]\n\u001B[0;32m     37\u001B[0m   },\n\u001B[0;32m     38\u001B[0m   {\n\u001B[0;32m     39\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     40\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m     41\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m     42\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m     43\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m     44\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimport numpy as np\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimport matplotlib.pyplot as plt\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom utils import *\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimport copy\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimport math\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mmatplotlib inline\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     50\u001B[0m    ]\n\u001B[0;32m     51\u001B[0m   },\n\u001B[0;32m     52\u001B[0m   {\n\u001B[0;32m     53\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     54\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m     55\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m     56\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m## 2 -  Problem Statement\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     58\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSuppose you are the CEO of a restaurant franchise and are considering different cities for opening a new outlet.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- You would like to expand your business to cities that may give your restaurant higher profits.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- The chain already has restaurants in various cities and you have data for profits and populations from the cities.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- You also have data on cities that are candidates for a new restaurant. \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     62\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    - For these cities, you have the city population.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan you use the data to help you identify which cities may potentially give your business higher profits?\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     66\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m## 3 - Dataset\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou will start by loading the dataset for this task. \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- The `load_data()` function shown below loads the data into variables `x_train` and `y_train`\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  - `x_train` is the population of a city\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     71\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  - `y_train` is the profit of a restaurant in that city. A negative value for profit indicates a loss.   \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  - Both `X_train` and `y_train` are numpy arrays.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     73\u001B[0m    ]\n\u001B[0;32m     74\u001B[0m   },\n\u001B[0;32m     75\u001B[0m   {\n\u001B[0;32m     76\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     77\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m     78\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m     79\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m     80\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m     81\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# load the dataset\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_train, y_train = load_data()\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     83\u001B[0m    ]\n\u001B[0;32m     84\u001B[0m   },\n\u001B[0;32m     85\u001B[0m   {\n\u001B[0;32m     86\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     87\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m     88\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#### View the variables\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     90\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBefore starting on any task, it is useful to get more familiar with your dataset.  \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     91\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- A good place to start is to just print out each variable and see what it contains.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     92\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe code below prints the variable `x_train` and the type of the variable.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     94\u001B[0m    ]\n\u001B[0;32m     95\u001B[0m   },\n\u001B[0;32m     96\u001B[0m   {\n\u001B[0;32m     97\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     98\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m3\u001B[39m,\n\u001B[0;32m     99\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    100\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    101\u001B[0m     {\n\u001B[0;32m    102\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstdout\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    103\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    104\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    105\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mType of x_train: <class \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumpy.ndarray\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    106\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFirst five elements of x_train are:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    107\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m [6.1101 5.5277 8.5186 7.0032 5.8598]\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    108\u001B[0m      ]\n\u001B[0;32m    109\u001B[0m     }\n\u001B[0;32m    110\u001B[0m    ],\n\u001B[0;32m    111\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    112\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# print x_train\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    113\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprint(\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mType of x_train:\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m,type(x_train))\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprint(\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mFirst five elements of x_train are:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mn\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m, x_train[:5]) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    115\u001B[0m    ]\n\u001B[0;32m    116\u001B[0m   },\n\u001B[0;32m    117\u001B[0m   {\n\u001B[0;32m    118\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    119\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    120\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`x_train` is a numpy array that contains decimal values that are all greater than zero.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    122\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- These values represent the city population times 10,000\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    123\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- For example, 6.1101 means that the population for that city is 61,101\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNow, let\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms print `y_train`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    126\u001B[0m    ]\n\u001B[0;32m    127\u001B[0m   },\n\u001B[0;32m    128\u001B[0m   {\n\u001B[0;32m    129\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    130\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m4\u001B[39m,\n\u001B[0;32m    131\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    132\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    133\u001B[0m     {\n\u001B[0;32m    134\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstdout\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    135\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    136\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    137\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mType of y_train: <class \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumpy.ndarray\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    138\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFirst five elements of y_train are:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    139\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m [17.592   9.1302 13.662  11.854   6.8233]\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    140\u001B[0m      ]\n\u001B[0;32m    141\u001B[0m     }\n\u001B[0;32m    142\u001B[0m    ],\n\u001B[0;32m    143\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# print y_train\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprint(\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mType of y_train:\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m,type(y_train))\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprint(\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mFirst five elements of y_train are:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mn\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m, y_train[:5])  \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    147\u001B[0m    ]\n\u001B[0;32m    148\u001B[0m   },\n\u001B[0;32m    149\u001B[0m   {\n\u001B[0;32m    150\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    151\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    152\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    153\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSimilarly, `y_train` is a numpy array that has decimal values, some negative, some positive.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    154\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- These represent your restaurant\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms average monthly profits in each city, in units of \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124m$10,000.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  - For example, 17.592 represents \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124m$175,920 in average monthly profits for that city.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    156\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  - -2.6807 represents -\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124m$26,807 in average monthly loss for that city.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    157\u001B[0m    ]\n\u001B[0;32m    158\u001B[0m   },\n\u001B[0;32m    159\u001B[0m   {\n\u001B[0;32m    160\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    161\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    162\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#### Check the dimensions of your variables\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAnother useful way to get familiar with your data is to view its dimensions.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease print the shape of `x_train` and `y_train` and see how many training examples you have in your dataset.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    168\u001B[0m    ]\n\u001B[0;32m    169\u001B[0m   },\n\u001B[0;32m    170\u001B[0m   {\n\u001B[0;32m    171\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    172\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m5\u001B[39m,\n\u001B[0;32m    173\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    174\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    175\u001B[0m     {\n\u001B[0;32m    176\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstdout\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    177\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    178\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    179\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe shape of x_train is: (97,)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    180\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe shape of y_train is:  (97,)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    181\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of training examples (m): 97\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    182\u001B[0m      ]\n\u001B[0;32m    183\u001B[0m     }\n\u001B[0;32m    184\u001B[0m    ],\n\u001B[0;32m    185\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    186\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprint (\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe shape of x_train is:\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, x_train.shape)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprint (\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe shape of y_train is: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, y_train.shape)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    188\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprint (\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNumber of training examples (m):\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, len(x_train))\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    189\u001B[0m    ]\n\u001B[0;32m    190\u001B[0m   },\n\u001B[0;32m    191\u001B[0m   {\n\u001B[0;32m    192\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    193\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    194\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    195\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe city population array has 97 data points, and the monthly average profits also has 97 data points. These are NumPy 1D arrays.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    196\u001B[0m    ]\n\u001B[0;32m    197\u001B[0m   },\n\u001B[0;32m    198\u001B[0m   {\n\u001B[0;32m    199\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    200\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    201\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    202\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#### Visualize your data\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    204\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is often useful to understand the data by visualizing it. \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- For this dataset, you can use a scatter plot to visualize the data, since it has only two properties to plot (profit and population). \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- Many other problems that you will encounter in real life have more than two properties (for example, population, average household income, monthly profits, monthly sales).When you have more than two properties, you can still use a scatter plot to see the relationship between each pair of properties.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    207\u001B[0m    ]\n\u001B[0;32m    208\u001B[0m   },\n\u001B[0;32m    209\u001B[0m   {\n\u001B[0;32m    210\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    211\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m6\u001B[39m,\n\u001B[0;32m    212\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    213\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    214\u001B[0m     {\n\u001B[0;32m    215\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[0;32m    216\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage/png\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;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\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    217\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext/plain\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    218\u001B[0m        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<Figure size 432x288 with 1 Axes>\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    219\u001B[0m       ]\n\u001B[0;32m    220\u001B[0m      },\n\u001B[0;32m    221\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[0;32m    222\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mneeds_background\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlight\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    223\u001B[0m      },\n\u001B[0;32m    224\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisplay_data\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    225\u001B[0m     }\n\u001B[0;32m    226\u001B[0m    ],\n\u001B[0;32m    227\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Create a scatter plot of the data. To change the markers to red \u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mx\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# we used the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmarker\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mc\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m parameters\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplt.scatter(x_train, y_train, marker=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, c=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m) \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    231\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Set the title\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplt.title(\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mProfits vs. Population per city\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Set the y-axis label\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplt.ylabel(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mProfit in $10,000\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    236\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Set the x-axis label\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplt.xlabel(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPopulation of City in 10,000s\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    238\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplt.show()\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    239\u001B[0m    ]\n\u001B[0;32m    240\u001B[0m   },\n\u001B[0;32m    241\u001B[0m   {\n\u001B[0;32m    242\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    243\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    244\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYour goal is to build a linear regression model to fit this data.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- With this model, you can then input a new city\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms population, and have the model estimate your restaurant\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms potential monthly profits for that city.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    247\u001B[0m    ]\n\u001B[0;32m    248\u001B[0m   },\n\u001B[0;32m    249\u001B[0m   {\n\u001B[0;32m    250\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    251\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    252\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    253\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<a name=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m4\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m></a>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    254\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m## 4 - Refresher on linear regression\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    255\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    256\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn this practice lab, you will fit the linear regression parameters $(w,b)$ to your dataset.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    257\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- The model function for linear regression, which is a function that maps from `x` (city population) to `y` (your restaurant\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms monthly profit for that city) is represented as \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    258\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    $$f_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mw,b}(x) = wx + b$$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- To train a linear regression model, you want to find the best $(w,b)$ parameters that fit your dataset.  \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    262\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    263\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    - To compare how one choice of $(w,b)$ is better or worse than another choice, you can evaluate it with a cost function $J(w,b)$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    264\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      - $J$ is a function of $(w,b)$. That is, the value of the cost $J(w,b)$ depends on the value of $(w,b)$.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    265\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    266\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    - The choice of $(w,b)$ that fits your data the best is the one that has the smallest cost $J(w,b)$.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    267\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    268\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    269\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- To find the values $(w,b)$ that gets the smallest possible cost $J(w,b)$, you can use a method called **gradient descent**. \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    270\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  - With each step of gradient descent, your parameters $(w,b)$ come closer to the optimal values that will achieve the lowest cost $J(w,b)$.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    271\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    272\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    273\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- The trained linear regression model can then take the input feature $x$ (city population) and output a prediction $f_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mw,b}(x)$ (predicted monthly profit for a restaurant in that city).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    274\u001B[0m    ]\n\u001B[0;32m    275\u001B[0m   },\n\u001B[0;32m    276\u001B[0m   {\n\u001B[0;32m    277\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    278\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    279\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    280\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<a name=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m5\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m></a>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    281\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m## 5 - Compute Cost\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    282\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    283\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGradient descent involves repeated steps to adjust the value of your parameter $(w,b)$ to gradually get a smaller and smaller cost $J(w,b)$.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    284\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- At each step of gradient descent, it will be helpful for you to monitor your progress by computing the cost $J(w,b)$ as $(w,b)$ gets updated. \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- In this section, you will implement a function to calculate $J(w,b)$ so that you can check the progress of your gradient descent implementation.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#### Cost function\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    288\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAs you may recall from the lecture, for one variable, the cost function for linear regression $J(w,b)$ is defined as\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    290\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m$$J(w,b) = \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124msum\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mlimits_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mi = 0}^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mm-1} (f_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mw,b}(x^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}) - y^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)})^2$$ \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    291\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    292\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- You can think of $f_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mw,b}(x^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)})$ as the model\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms prediction of your restaurant\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms profit, as opposed to $y^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}$, which is the actual profit that is recorded in the data.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- $m$ is the number of training examples in the dataset\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    294\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    295\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#### Model prediction\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    296\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    297\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- For linear regression with one variable, the prediction of the model $f_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mw,b}$ for an example $x^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}$ is representented as:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    298\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    299\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m$$ f_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mw,b}(x^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}) = wx^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)} + b$$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    300\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    301\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis is the equation for a line, with an intercept $b$ and a slope $w$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    302\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    303\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#### Implementation\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    305\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease complete the `compute_cost()` function below to compute the cost $J(w,b)$.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    306\u001B[0m    ]\n\u001B[0;32m    307\u001B[0m   },\n\u001B[0;32m    308\u001B[0m   {\n\u001B[0;32m    309\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    310\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    311\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<a name=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mex01\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m></a>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    313\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m### Exercise 1\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    314\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    315\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplete the `compute_cost` below to:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    316\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m* Iterate over the training examples, and for each example, compute:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    * The prediction of the model for that example \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    $$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    f_\u001B[39m\u001B[38;5;132;01m{wb}\u001B[39;00m\u001B[38;5;124m(x^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}) =  wx^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)} + b \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    321\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    $$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m   \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    323\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    * The cost for that example  $$cost^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)} =  (f_\u001B[39m\u001B[38;5;132;01m{wb}\u001B[39;00m\u001B[38;5;124m - y^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)})^2$$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    324\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    325\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m* Return the total cost over all examples\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    327\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m$$J(\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mmathbf\u001B[39m\u001B[38;5;132;01m{w}\u001B[39;00m\u001B[38;5;124m,b) = \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124msum\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mlimits_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mi = 0}^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mm-1} cost^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}$$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    328\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  * Here, $m$ is the number of training examples and $\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124msum$ is the summation operator\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    329\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    330\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf you get stuck, you can check out the hints presented after the cell below to help you with the implementation.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    331\u001B[0m    ]\n\u001B[0;32m    332\u001B[0m   },\n\u001B[0;32m    333\u001B[0m   {\n\u001B[0;32m    334\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    335\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m9\u001B[39m,\n\u001B[0;32m    336\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    337\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m    338\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    339\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# UNQ_C1\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    340\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# GRADED FUNCTION: compute_cost\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    341\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    342\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdef compute_cost(x, y, w, b): \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    343\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    344\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    Computes the cost function for linear regression.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    345\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    346\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    Args:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    347\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        x (ndarray): Shape (m,) Input to the model (Population of cities) \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        y (ndarray): Shape (m,) Label (Actual profits for the cities)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    349\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        w, b (scalar): Parameters of the model\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    350\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    351\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    Returns\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    352\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        total_cost (float): The cost of using w,b as the parameters for linear regression\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    353\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m               to fit the data points in x and y\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    354\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    355\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    # number of training examples\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    356\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    m = x.shape[0] \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    357\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    358\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    # You need to return this variable correctly\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    359\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    total_cost = 0\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    360\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    361\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    ### START CODE HERE ###  \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    362\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    363\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    ### END CODE HERE ### \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    364\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    365\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    return total_cost\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    366\u001B[0m    ]\n\u001B[0;32m    367\u001B[0m   },\n\u001B[0;32m    368\u001B[0m   {\n\u001B[0;32m    369\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    370\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    371\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    372\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    373\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  <summary><font size=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m3\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m color=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mdarkgreen\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m><b>Click for hints</b></font></summary>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    374\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    375\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    376\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m   * You can represent a summation operator eg: $h = \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124msum\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mlimits_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mi = 0}^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mm-1} 2i$ in code as follows:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    377\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m     ```python \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    378\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    h = 0\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    379\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    for i in range(m):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    380\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        h = h + 2*i\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    381\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    ```\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    382\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    383\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m   * In this case, you can iterate over all the examples in `x` using a for loop and add the `cost` from each iteration to a variable (`cost_sum`) initialized outside the loop.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    384\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    385\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m   * Then, you can return the `total_cost` as `cost_sum` divided by `2m`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    386\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m     \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          <summary><font size=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m2\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m color=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mdarkblue\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m><b> Click for more hints</b></font></summary>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    389\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    390\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    * Here\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms how you can structure the overall implementation for this function\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    391\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    ```python \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    392\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    def compute_cost(x, y, w, b):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    393\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # number of training examples\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    394\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        m = x.shape[0] \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    395\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    396\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # You need to return this variable correctly\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        total_cost = 0\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    398\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    399\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        ### START CODE HERE ###  \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Variable to keep track of sum of cost from each example\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    401\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        cost_sum = 0\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    402\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    403\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Loop over training examples\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    404\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        for i in range(m):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    405\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            # Your code here to get the prediction f_wb for the ith example\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    406\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            f_wb = \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    407\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            # Your code here to get the cost associated with the ith example\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    408\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            cost = \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    409\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    410\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            # Add to sum of cost for each example\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    411\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            cost_sum = cost_sum + cost \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    412\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    413\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Get the total cost as the sum divided by (2*m)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    414\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        total_cost = (1 / (2 * m)) * cost_sum\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    415\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        ### END CODE HERE ### \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    416\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    417\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        return total_cost\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    418\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    ```\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    419\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    420\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    If you\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mre still stuck, you can check the hints presented below to figure out how to calculate `f_wb` and `cost`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    421\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    422\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    423\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          <summary><font size=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m2\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m color=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mdarkblue\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m><b>Hint to calculate f_wb</b></font></summary>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    424\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m           &emsp; &emsp; For scalars $a$, $b$ and $c$ (<code>x[i]</code>, <code>w</code> and <code>b</code> are all scalars), you can calculate the equation $h = ab + c$ in code as <code>h = a * b + c</code>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    425\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          <details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    426\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m              <summary><font size=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m2\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m color=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mblue\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m><b>&emsp; &emsp; More hints to calculate f</b></font></summary>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    427\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m               &emsp; &emsp; You can compute f_wb as <code>f_wb = w * x[i] + b </code>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    428\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m           </details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    429\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    </details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    430\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    431\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m     <details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    432\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          <summary><font size=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m2\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m color=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mdarkblue\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m><b>Hint to calculate cost</b></font></summary>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    433\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          &emsp; &emsp; You can calculate the square of a variable z as z**2\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    434\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          <details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    435\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m              <summary><font size=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m2\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m color=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mblue\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m><b>&emsp; &emsp; More hints to calculate cost</b></font></summary>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    436\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m              &emsp; &emsp; You can compute cost as <code>cost = (f_wb - y[i]) ** 2</code>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    437\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          </details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    438\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    </details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    440\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    </details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    441\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    442\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m</details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    443\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    444\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    445\u001B[0m    ]\n\u001B[0;32m    446\u001B[0m   },\n\u001B[0;32m    447\u001B[0m   {\n\u001B[0;32m    448\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    449\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    450\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    451\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can check if your implementation was correct by running the following test code:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    452\u001B[0m    ]\n\u001B[0;32m    453\u001B[0m   },\n\u001B[0;32m    454\u001B[0m   {\n\u001B[0;32m    455\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    456\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m10\u001B[39m,\n\u001B[0;32m    457\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    458\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    459\u001B[0m     {\n\u001B[0;32m    460\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstdout\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    461\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    462\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    463\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<class \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumpy.float64\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    464\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCost at initial w (zeros): 75.203\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    465\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\u001b\u001B[39;00m\u001B[38;5;124m[92mAll tests passed!\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    466\u001B[0m      ]\n\u001B[0;32m    467\u001B[0m     }\n\u001B[0;32m    468\u001B[0m    ],\n\u001B[0;32m    469\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    470\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Compute cost with some initial values for paramaters w, b\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    471\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minitial_w = 2\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    472\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minitial_b = 1\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    473\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    474\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcost = compute_cost(x_train, y_train, initial_w, initial_b)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    475\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprint(type(cost))\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    476\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprint(f\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCost at initial w (zeros): \u001B[39m\u001B[38;5;132;01m{cost:.3f}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    477\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Public tests\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    479\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom public_tests import *\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    480\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompute_cost_test(compute_cost)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    481\u001B[0m    ]\n\u001B[0;32m    482\u001B[0m   },\n\u001B[0;32m    483\u001B[0m   {\n\u001B[0;32m    484\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    485\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    486\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    487\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m**Expected Output**:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    488\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<table>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    489\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  <tr>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    490\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <td> <b>Cost at initial w (zeros):<b> 75.203 </td> \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    491\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  </tr>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    492\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m</table>\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    493\u001B[0m    ]\n\u001B[0;32m    494\u001B[0m   },\n\u001B[0;32m    495\u001B[0m   {\n\u001B[0;32m    496\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    497\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    498\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    499\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<a name=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m6\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m></a>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    500\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m## 6 - Gradient descent \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    501\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    502\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn this section, you will implement the gradient for parameters $w, b$ for linear regression. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    503\u001B[0m    ]\n\u001B[0;32m    504\u001B[0m   },\n\u001B[0;32m    505\u001B[0m   {\n\u001B[0;32m    506\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    507\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    508\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    509\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAs described in the lecture videos, the gradient descent algorithm is:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    510\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    511\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m$$\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mbegin\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124malign*}& \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mrepeat until convergence:} \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124m; \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mlbrace \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mnewline \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124m; & \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mphantom \u001B[39m\u001B[38;5;132;01m{0000}\u001B[39;00m\u001B[38;5;124m b := b -  \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124malpha \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial J(w,b)}\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial b} \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mnewline       \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124m; & \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mphantom \u001B[39m\u001B[38;5;132;01m{0000}\u001B[39;00m\u001B[38;5;124m w := w -  \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124malpha \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial J(w,b)}\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial w} \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mtag\u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m  \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124m; & \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    512\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mnewline & \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mrbrace\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124malign*}$$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    513\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    514\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhere, parameters $w, b$ are both updated simultaniously and where  \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    515\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m$$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial J(w,b)}\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial b}  = \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124msum\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mlimits_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mi = 0}^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mm-1} (f_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mw,b}(x^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}) - y^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}) \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mtag\u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    517\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m$$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    518\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m$$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    519\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial J(w,b)}\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial w}  = \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124msum\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mlimits_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mi = 0}^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mm-1} (f_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mw,b}(x^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}) -y^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)})x^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)} \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mtag\u001B[39m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    520\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m$$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    521\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m* m is the number of training examples in the dataset\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    522\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    523\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    524\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*  $f_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mw,b}(x^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)})$ is the model\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms prediction, while $y^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}$, is the target value\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    525\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    526\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    527\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou will implement a function called `compute_gradient` which calculates $\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial J(w)}\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial w}$, $\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial J(w)}\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial b}$ \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    528\u001B[0m    ]\n\u001B[0;32m    529\u001B[0m   },\n\u001B[0;32m    530\u001B[0m   {\n\u001B[0;32m    531\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    532\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    533\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    534\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<a name=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mex02\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m></a>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    535\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m### Exercise 2\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    536\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    537\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease complete the `compute_gradient` function to:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    538\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    539\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m* Iterate over the training examples, and for each example, compute:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    540\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    * The prediction of the model for that example \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    541\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    $$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    542\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    f_\u001B[39m\u001B[38;5;132;01m{wb}\u001B[39;00m\u001B[38;5;124m(x^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}) =  wx^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)} + b \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    543\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    $$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    544\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m   \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    545\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    * The gradient for the parameters $w, b$ from that example \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    546\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        $$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    547\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial J(w,b)}\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial b}^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}  =  (f_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mw,b}(x^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}) - y^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}) \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    548\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        $$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    549\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        $$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    550\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial J(w,b)}\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial w}^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}  =  (f_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mw,b}(x^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}) -y^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)})x^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)} \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    551\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        $$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    552\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    553\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    554\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m* Return the total gradient update from all the examples\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    555\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    $$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    556\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial J(w,b)}\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial b}  = \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124msum\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mlimits_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mi = 0}^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mm-1} \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial J(w,b)}\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial b}^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    $$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    558\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    559\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    $$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    560\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial J(w,b)}\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial w}  = \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124msum\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mlimits_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mi = 0}^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mm-1} \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfrac\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial J(w,b)}\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpartial w}^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)} \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    561\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    $$\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    562\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  * Here, $m$ is the number of training examples and $\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124msum$ is the summation operator\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    563\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    564\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf you get stuck, you can check out the hints presented after the cell below to help you with the implementation.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    565\u001B[0m    ]\n\u001B[0;32m    566\u001B[0m   },\n\u001B[0;32m    567\u001B[0m   {\n\u001B[0;32m    568\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m--> 569\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mnull\u001B[49m,\n\u001B[0;32m    570\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    571\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m    572\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    573\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# UNQ_C2\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    574\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# GRADED FUNCTION: compute_gradient\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    575\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdef compute_gradient(x, y, w, b): \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    576\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    577\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    Computes the gradient for linear regression \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    Args:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    579\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      x (ndarray): Shape (m,) Input to the model (Population of cities) \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    580\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      y (ndarray): Shape (m,) Label (Actual profits for the cities)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    581\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      w, b (scalar): Parameters of the model  \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    582\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    Returns\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    583\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      dj_dw (scalar): The gradient of the cost w.r.t. the parameters w\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    584\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      dj_db (scalar): The gradient of the cost w.r.t. the parameter b     \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m     \u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    587\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    # Number of training examples\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    588\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    m = x.shape[0]\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    589\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    590\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    # You need to return the following variables correctly\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    591\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    dj_dw = 0\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    592\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    dj_db = 0\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    593\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    594\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    ### START CODE HERE ### \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    595\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    596\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    ### END CODE HERE ### \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    597\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    598\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    return dj_dw, dj_db\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    599\u001B[0m    ]\n\u001B[0;32m    600\u001B[0m   },\n\u001B[0;32m    601\u001B[0m   {\n\u001B[0;32m    602\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    603\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    604\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    605\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    606\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  <summary><font size=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m3\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m color=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mdarkgreen\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m><b>Click for hints</b></font></summary>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    607\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m       \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    * You can represent a summation operator eg: $h = \u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124msum\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mlimits_\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mi = 0}^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mm-1} 2i$ in code as follows:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    609\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m     ```python \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    610\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    h = 0\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    611\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    for i in range(m):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    612\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        h = h + 2*i\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    613\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    ```\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    614\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    615\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    * In this case, you can iterate over all the examples in `x` using a for loop and for each example, keep adding the gradient from that example to the variables `dj_dw` and `dj_db` which are initialized outside the loop. \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    616\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m   * Then, you can return `dj_dw` and `dj_db` both divided by `m`.    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    618\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    619\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          <summary><font size=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m2\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m color=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mdarkblue\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m><b> Click for more hints</b></font></summary>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    620\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    621\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    * Here\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms how you can structure the overall implementation for this function\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    622\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    ```python \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    def compute_gradient(x, y, w, b): \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    624\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    625\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        Computes the gradient for linear regression \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    626\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        Args:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    627\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          x (ndarray): Shape (m,) Input to the model (Population of cities) \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          y (ndarray): Shape (m,) Label (Actual profits for the cities)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          w, b (scalar): Parameters of the model  \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        Returns\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          dj_dw (scalar): The gradient of the cost w.r.t. the parameters w\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          dj_db (scalar): The gradient of the cost w.r.t. the parameter b     \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    633\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m         \u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    634\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    635\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Number of training examples\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    636\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        m = x.shape[0]\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    637\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    638\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # You need to return the following variables correctly\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    639\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        dj_dw = 0\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    640\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        dj_db = 0\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    641\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    642\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        ### START CODE HERE ### \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    643\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Loop over examples\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    644\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        for i in range(m):  \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    645\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            # Your code here to get prediction f_wb for the ith example\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    646\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            f_wb = \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    647\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    648\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            # Your code here to get the gradient for w from the ith example \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    649\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            dj_dw_i = \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    650\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    651\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            # Your code here to get the gradient for b from the ith example \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    652\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            dj_db_i = \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    653\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m     \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    654\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            # Update dj_db : In Python, a += 1  is the same as a = a + 1\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    655\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            dj_db += dj_db_i\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    656\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    657\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            # Update dj_dw\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    658\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            dj_dw += dj_dw_i\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    659\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    660\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Divide both dj_dw and dj_db by m\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    661\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        dj_dw = dj_dw / m\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    662\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        dj_db = dj_db / m\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    663\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        ### END CODE HERE ### \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    664\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    665\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        return dj_dw, dj_db\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    666\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    ```\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    667\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    668\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    If you\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mre still stuck, you can check the hints presented below to figure out how to calculate `f_wb` and `cost`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    669\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    670\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    671\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          <summary><font size=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m2\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m color=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mdarkblue\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m><b>Hint to calculate f_wb</b></font></summary>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    672\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m           &emsp; &emsp; You did this in the previous exercise! For scalars $a$, $b$ and $c$ (<code>x[i]</code>, <code>w</code> and <code>b</code> are all scalars), you can calculate the equation $h = ab + c$ in code as <code>h = a * b + c</code>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    673\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          <details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    674\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m              <summary><font size=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m2\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m color=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mblue\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m><b>&emsp; &emsp; More hints to calculate f</b></font></summary>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    675\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m               &emsp; &emsp; You can compute f_wb as <code>f_wb = w * x[i] + b </code>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m           </details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    677\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    </details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    678\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    679\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    680\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          <summary><font size=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m2\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m color=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mdarkblue\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m><b>Hint to calculate dj_dw_i</b></font></summary>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    681\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m           &emsp; &emsp; For scalars $a$, $b$ and $c$ (<code>f_wb</code>, <code>y[i]</code> and <code>x[i]</code> are all scalars), you can calculate the equation $h = (a - b)c$ in code as <code>h = (a-b)*c</code>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    682\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          <details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    683\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m              <summary><font size=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m2\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m color=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mblue\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m><b>&emsp; &emsp; More hints to calculate f</b></font></summary>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    684\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m               &emsp; &emsp; You can compute dj_dw_i as <code>dj_dw_i = (f_wb - y[i]) * x[i] </code>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    685\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m           </details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    686\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    </details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    687\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    688\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    689\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          <summary><font size=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m2\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m color=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mdarkblue\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m><b>Hint to calculate dj_db_i</b></font></summary>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    690\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m             &emsp; &emsp; You can compute dj_db_i as <code> dj_db_i = f_wb - y[i] </code>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    691\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    </details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    692\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    693\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    </details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    694\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    695\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m</details>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    696\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    697\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    698\u001B[0m    ]\n\u001B[0;32m    699\u001B[0m   },\n\u001B[0;32m    700\u001B[0m   {\n\u001B[0;32m    701\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    702\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    703\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRun the cells below to check your implementation of the `compute_gradient` function with two different initializations of the parameters $w$,$b$.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    705\u001B[0m    ]\n\u001B[0;32m    706\u001B[0m   },\n\u001B[0;32m    707\u001B[0m   {\n\u001B[0;32m    708\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    709\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: null,\n\u001B[0;32m    710\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    711\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m    712\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Compute and display gradient with w initialized to zeroes\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    714\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minitial_w = 0\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    715\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minitial_b = 0\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    716\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    717\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtmp_dj_dw, tmp_dj_db = compute_gradient(x_train, y_train, initial_w, initial_b)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    718\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprint(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGradient at initial w, b (zeros):\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, tmp_dj_dw, tmp_dj_db)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    719\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    720\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompute_gradient_test(compute_gradient)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    721\u001B[0m    ]\n\u001B[0;32m    722\u001B[0m   },\n\u001B[0;32m    723\u001B[0m   {\n\u001B[0;32m    724\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    725\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    726\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    727\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNow let\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms run the gradient descent algorithm implemented above on our dataset.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    728\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    729\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m**Expected Output**:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    730\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<table>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    731\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  <tr>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    732\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <td> <b>Gradient at initial , b (zeros)<b></td>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    733\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <td> -65.32884975 -5.83913505154639</td> \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    734\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  </tr>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    735\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m</table>\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    736\u001B[0m    ]\n\u001B[0;32m    737\u001B[0m   },\n\u001B[0;32m    738\u001B[0m   {\n\u001B[0;32m    739\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    740\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: null,\n\u001B[0;32m    741\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    742\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m    743\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    744\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Compute and display cost and gradient with non-zero w\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    745\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_w = 0.2\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    746\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_b = 0.2\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    747\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtmp_dj_dw, tmp_dj_db = compute_gradient(x_train, y_train, test_w, test_b)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    749\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprint(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGradient at test w, b:\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, tmp_dj_dw, tmp_dj_db)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    750\u001B[0m    ]\n\u001B[0;32m    751\u001B[0m   },\n\u001B[0;32m    752\u001B[0m   {\n\u001B[0;32m    753\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    754\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    755\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    756\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m**Expected Output**:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    757\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<table>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  <tr>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    759\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <td> <b>Gradient at test w<b></td>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    760\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <td> -47.41610118 -4.007175051546391</td> \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    761\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  </tr>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    762\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m</table>\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    763\u001B[0m    ]\n\u001B[0;32m    764\u001B[0m   },\n\u001B[0;32m    765\u001B[0m   {\n\u001B[0;32m    766\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    767\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    768\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    769\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<a name=\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m2.6\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m></a>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    770\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m### 2.6 Learning parameters using batch gradient descent \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    771\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    772\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou will now find the optimal parameters of a linear regression model by using batch gradient descent. Recall batch refers to running all the examples in one iteration.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    773\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- You don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt need to implement anything for this part. Simply run the cells below. \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    774\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    775\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- A good way to verify that gradient descent is working correctly is to look\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mat the value of $J(w,b)$ and check that it is decreasing with each step. \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    777\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    778\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- Assuming you have implemented the gradient and computed the cost correctly and you have an appropriate value for the learning rate alpha, $J(w,b)$ should never increase and should converge to a steady value by the end of the algorithm.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    779\u001B[0m    ]\n\u001B[0;32m    780\u001B[0m   },\n\u001B[0;32m    781\u001B[0m   {\n\u001B[0;32m    782\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    783\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: null,\n\u001B[0;32m    784\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    785\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m    786\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    787\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdef gradient_descent(x, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    788\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    789\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    Performs batch gradient descent to learn theta. Updates theta by taking \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    790\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    num_iters gradient steps with learning rate alpha\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    791\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    792\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    Args:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    793\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      x :    (ndarray): Shape (m,)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    794\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      y :    (ndarray): Shape (m,)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    795\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      w_in, b_in : (scalar) Initial values of parameters of the model\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      cost_function: function to compute cost\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    797\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      gradient_function: function to compute the gradient\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    798\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      alpha : (float) Learning rate\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      num_iters : (int) number of iterations to run gradient descent\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    800\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    Returns\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    801\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      w : (ndarray): Shape (1,) Updated values of parameters of the model after\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    802\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          running gradient descent\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    803\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m      b : (scalar)                Updated value of parameter of the model after\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    804\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m          running gradient descent\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    805\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    806\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    807\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    # number of training examples\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    808\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    m = len(x)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    809\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    810\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    # An array to store cost J and w\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms at each iteration  primarily for graphing later\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    811\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    J_history = []\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    812\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    w_history = []\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    813\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    w = copy.deepcopy(w_in)  #avoid modifying global w within function\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    814\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    b = b_in\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    815\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    816\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    for i in range(num_iters):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    817\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    818\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Calculate the gradient and update the parameters\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    819\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        dj_dw, dj_db = gradient_function(x, y, w, b )  \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    820\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    821\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Update Parameters using w, b, alpha and gradient\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    822\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        w = w - alpha * dj_dw               \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    823\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        b = b - alpha * dj_db               \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    824\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    825\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Save cost J at each iteration\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    826\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        if i<100000:      # prevent resource exhaustion \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    827\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            cost =  cost_function(x, y, w, b)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    828\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            J_history.append(cost)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    829\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    830\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Print cost every at intervals 10 times or as many iterations if < 10\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    831\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        if i\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m math.ceil(num_iters/10) == 0:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    832\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            w_history.append(w)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    833\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m            print(f\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mIteration \u001B[39m\u001B[38;5;132;01m{i:4}\u001B[39;00m\u001B[38;5;124m: Cost \u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124mfloat(J_history[-1]):8.2f}   \u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    834\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    835\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    return w, b, J_history, w_history #return w and J,w history for graphing\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    836\u001B[0m    ]\n\u001B[0;32m    837\u001B[0m   },\n\u001B[0;32m    838\u001B[0m   {\n\u001B[0;32m    839\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    840\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    841\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    842\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNow let\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms run the gradient descent algorithm above to learn the parameters for our dataset.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    843\u001B[0m    ]\n\u001B[0;32m    844\u001B[0m   },\n\u001B[0;32m    845\u001B[0m   {\n\u001B[0;32m    846\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    847\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: null,\n\u001B[0;32m    848\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    849\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m    850\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    851\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# initialize fitting parameters. Recall that the shape of w is (n,)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    852\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minitial_w = 0.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    853\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minitial_b = 0.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    854\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    855\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# some gradient descent settings\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    856\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miterations = 1500\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    857\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malpha = 0.01\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    858\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    859\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw,b,_,_ = gradient_descent(x_train ,y_train, initial_w, initial_b, \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    860\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m                     compute_cost, compute_gradient, alpha, iterations)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    861\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprint(\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mw,b found by gradient descent:\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m, w, b)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    862\u001B[0m    ]\n\u001B[0;32m    863\u001B[0m   },\n\u001B[0;32m    864\u001B[0m   {\n\u001B[0;32m    865\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    866\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    867\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    868\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m**Expected Output**:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<table>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  <tr>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <td> <b> w, b found by gradient descent<b></td>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    872\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <td> 1.16636235 -3.63029143940436</td> \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    873\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  </tr>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    874\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m</table>\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    875\u001B[0m    ]\n\u001B[0;32m    876\u001B[0m   },\n\u001B[0;32m    877\u001B[0m   {\n\u001B[0;32m    878\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    879\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    880\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    881\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWe will now use the final parameters from gradient descent to plot the linear fit. \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    882\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    883\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRecall that we can get the prediction for a single example $f(x^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)})= wx^\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(i)}+b$. \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    884\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    885\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo calculate the predictions on the entire dataset, we can loop through all the training examples and calculate the prediction for each example. This is shown in the code block below.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    886\u001B[0m    ]\n\u001B[0;32m    887\u001B[0m   },\n\u001B[0;32m    888\u001B[0m   {\n\u001B[0;32m    889\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    890\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: null,\n\u001B[0;32m    891\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    892\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m    893\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    894\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mm = x_train.shape[0]\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    895\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredicted = np.zeros(m)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    896\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    897\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfor i in range(m):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    898\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    predicted[i] = w * x_train[i] + b\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    899\u001B[0m    ]\n\u001B[0;32m    900\u001B[0m   },\n\u001B[0;32m    901\u001B[0m   {\n\u001B[0;32m    902\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    903\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    904\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    905\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWe will now plot the predicted values to see the linear fit.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    906\u001B[0m    ]\n\u001B[0;32m    907\u001B[0m   },\n\u001B[0;32m    908\u001B[0m   {\n\u001B[0;32m    909\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    910\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: null,\n\u001B[0;32m    911\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    912\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m    913\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    914\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Plot the linear fit\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    915\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplt.plot(x_train, predicted, c = \u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mb\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    916\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    917\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Create a scatter plot of the data. \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    918\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplt.scatter(x_train, y_train, marker=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, c=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m) \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    919\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    920\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Set the title\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    921\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplt.title(\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mProfits vs. Population per city\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    922\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Set the y-axis label\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    923\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplt.ylabel(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mProfit in $10,000\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    924\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Set the x-axis label\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    925\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplt.xlabel(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPopulation of City in 10,000s\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    926\u001B[0m    ]\n\u001B[0;32m    927\u001B[0m   },\n\u001B[0;32m    928\u001B[0m   {\n\u001B[0;32m    929\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    930\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    931\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    932\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYour final values of $w,b$ can also be used to make predictions on profits. Let\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms predict what the profit would be in areas of 35,000 and 70,000 people. \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    933\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    934\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- The model takes in population of a city in 10,000s as input. \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    935\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    936\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- Therefore, 35,000 people can be translated into an input to the model as `np.array([3.5])`\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    937\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    938\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- Similarly, 70,000 people can be translated into an input to the model as `np.array([7.])`\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    939\u001B[0m    ]\n\u001B[0;32m    940\u001B[0m   },\n\u001B[0;32m    941\u001B[0m   {\n\u001B[0;32m    942\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    943\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: null,\n\u001B[0;32m    944\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    945\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[0;32m    946\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    947\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict1 = 3.5 * w + b\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    948\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprint(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFor population = 35,000, we predict a profit of $\u001B[39m\u001B[38;5;132;01m%.2f\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m (predict1*10000))\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    949\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    950\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict2 = 7.0 * w + b\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    951\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprint(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFor population = 70,000, we predict a profit of $\u001B[39m\u001B[38;5;132;01m%.2f\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m (predict2*10000))\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    952\u001B[0m    ]\n\u001B[0;32m    953\u001B[0m   },\n\u001B[0;32m    954\u001B[0m   {\n\u001B[0;32m    955\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmarkdown\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    956\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {},\n\u001B[0;32m    957\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[0;32m    958\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m**Expected Output**:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    959\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<table>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    960\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  <tr>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    961\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <td> <b> For population = 35,000, we predict a profit of<b></td>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    962\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <td> $4519.77 </td> \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    963\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  </tr>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    964\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    965\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  <tr>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    966\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <td> <b> For population = 70,000, we predict a profit of<b></td>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    967\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    <td> $45342.45 </td> \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    968\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  </tr>\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    969\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m</table>\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    970\u001B[0m    ]\n\u001B[0;32m    971\u001B[0m   }\n\u001B[0;32m    972\u001B[0m  ],\n\u001B[0;32m    973\u001B[0m  \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[0;32m    974\u001B[0m   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkernelspec\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[0;32m    975\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisplay_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPython 3 (ipykernel)\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    976\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlanguage\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    977\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython3\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    978\u001B[0m   },\n\u001B[0;32m    979\u001B[0m   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlanguage_info\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[0;32m    980\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcodemirror_mode\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[0;32m    981\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mipython\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    982\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mversion\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m3\u001B[39m\n\u001B[0;32m    983\u001B[0m    },\n\u001B[0;32m    984\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile_extension\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.py\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    985\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmimetype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext/x-python\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    986\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    987\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnbconvert_exporter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    988\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpygments_lexer\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mipython3\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    989\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mversion\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m3.10.5\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    990\u001B[0m   }\n\u001B[0;32m    991\u001B[0m  },\n\u001B[0;32m    992\u001B[0m  \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnbformat\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m4\u001B[39m,\n\u001B[0;32m    993\u001B[0m  \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnbformat_minor\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m4\u001B[39m\n\u001B[0;32m    994\u001B[0m }\n",
      "\u001B[1;31mNameError\u001B[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Practice Lab: Linear Regression\\n\",\n",
    "    \"\\n\",\n",
    "    \"Welcome to your first practice lab! In this lab, you will implement linear regression with one variable to predict profits for a restaurant franchise.\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Outline\\n\",\n",
    "    \"- [ 1 - Packages ](#1)\\n\",\n",
    "    \"- [ 2 - Linear regression with one variable ](#2)\\n\",\n",
    "    \"  - [ 2.1 Problem Statement](#2.1)\\n\",\n",
    "    \"  - [ 2.2  Dataset](#2.2)\\n\",\n",
    "    \"  - [ 2.3 Refresher on linear regression](#2.3)\\n\",\n",
    "    \"  - [ 2.4  Compute Cost](#2.4)\\n\",\n",
    "    \"    - [ Exercise 1](#ex01)\\n\",\n",
    "    \"  - [ 2.5 Gradient descent ](#2.5)\\n\",\n",
    "    \"    - [ Exercise 2](#ex02)\\n\",\n",
    "    \"  - [ 2.6 Learning parameters using batch gradient descent ](#2.6)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"<a name=\\\"1\\\"></a>\\n\",\n",
    "    \"## 1 - Packages \\n\",\n",
    "    \"\\n\",\n",
    "    \"First, let's run the cell below to import all the packages that you will need during this assignment.\\n\",\n",
    "    \"- [numpy](www.numpy.org) is the fundamental package for working with matrices in Python.\\n\",\n",
    "    \"- [matplotlib](http://matplotlib.org) is a famous library to plot graphs in Python.\\n\",\n",
    "    \"- ``utils.py`` contains helper functions for this assignment. You do not need to modify code in this file.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 1,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from utils import *\\n\",\n",
    "    \"import copy\\n\",\n",
    "    \"import math\\n\",\n",
    "    \"%matplotlib inline\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2 -  Problem Statement\\n\",\n",
    "    \"\\n\",\n",
    "    \"Suppose you are the CEO of a restaurant franchise and are considering different cities for opening a new outlet.\\n\",\n",
    "    \"- You would like to expand your business to cities that may give your restaurant higher profits.\\n\",\n",
    "    \"- The chain already has restaurants in various cities and you have data for profits and populations from the cities.\\n\",\n",
    "    \"- You also have data on cities that are candidates for a new restaurant. \\n\",\n",
    "    \"    - For these cities, you have the city population.\\n\",\n",
    "    \"    \\n\",\n",
    "    \"Can you use the data to help you identify which cities may potentially give your business higher profits?\\n\",\n",
    "    \"\\n\",\n",
    "    \"## 3 - Dataset\\n\",\n",
    "    \"\\n\",\n",
    "    \"You will start by loading the dataset for this task. \\n\",\n",
    "    \"- The `load_data()` function shown below loads the data into variables `x_train` and `y_train`\\n\",\n",
    "    \"  - `x_train` is the population of a city\\n\",\n",
    "    \"  - `y_train` is the profit of a restaurant in that city. A negative value for profit indicates a loss.   \\n\",\n",
    "    \"  - Both `X_train` and `y_train` are numpy arrays.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 2,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# load the dataset\\n\",\n",
    "    \"x_train, y_train = load_data()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"#### View the variables\\n\",\n",
    "    \"Before starting on any task, it is useful to get more familiar with your dataset.  \\n\",\n",
    "    \"- A good place to start is to just print out each variable and see what it contains.\\n\",\n",
    "    \"\\n\",\n",
    "    \"The code below prints the variable `x_train` and the type of the variable.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 3,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Type of x_train: <class 'numpy.ndarray'>\\n\",\n",
    "      \"First five elements of x_train are:\\n\",\n",
    "      \" [6.1101 5.5277 8.5186 7.0032 5.8598]\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# print x_train\\n\",\n",
    "    \"print(\\\"Type of x_train:\\\",type(x_train))\\n\",\n",
    "    \"print(\\\"First five elements of x_train are:\\\\n\\\", x_train[:5]) \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"`x_train` is a numpy array that contains decimal values that are all greater than zero.\\n\",\n",
    "    \"- These values represent the city population times 10,000\\n\",\n",
    "    \"- For example, 6.1101 means that the population for that city is 61,101\\n\",\n",
    "    \"  \\n\",\n",
    "    \"Now, let's print `y_train`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 4,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Type of y_train: <class 'numpy.ndarray'>\\n\",\n",
    "      \"First five elements of y_train are:\\n\",\n",
    "      \" [17.592   9.1302 13.662  11.854   6.8233]\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# print y_train\\n\",\n",
    "    \"print(\\\"Type of y_train:\\\",type(y_train))\\n\",\n",
    "    \"print(\\\"First five elements of y_train are:\\\\n\\\", y_train[:5])  \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Similarly, `y_train` is a numpy array that has decimal values, some negative, some positive.\\n\",\n",
    "    \"- These represent your restaurant's average monthly profits in each city, in units of \\\\$10,000.\\n\",\n",
    "    \"  - For example, 17.592 represents \\\\$175,920 in average monthly profits for that city.\\n\",\n",
    "    \"  - -2.6807 represents -\\\\$26,807 in average monthly loss for that city.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"#### Check the dimensions of your variables\\n\",\n",
    "    \"\\n\",\n",
    "    \"Another useful way to get familiar with your data is to view its dimensions.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Please print the shape of `x_train` and `y_train` and see how many training examples you have in your dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 5,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"The shape of x_train is: (97,)\\n\",\n",
    "      \"The shape of y_train is:  (97,)\\n\",\n",
    "      \"Number of training examples (m): 97\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"print ('The shape of x_train is:', x_train.shape)\\n\",\n",
    "    \"print ('The shape of y_train is: ', y_train.shape)\\n\",\n",
    "    \"print ('Number of training examples (m):', len(x_train))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"The city population array has 97 data points, and the monthly average profits also has 97 data points. These are NumPy 1D arrays.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"#### Visualize your data\\n\",\n",
    "    \"\\n\",\n",
    "    \"It is often useful to understand the data by visualizing it. \\n\",\n",
    "    \"- For this dataset, you can use a scatter plot to visualize the data, since it has only two properties to plot (profit and population). \\n\",\n",
    "    \"- Many other problems that you will encounter in real life have more than two properties (for example, population, average household income, monthly profits, monthly sales).When you have more than two properties, you can still use a scatter plot to see the relationship between each pair of properties.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 6,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"image/png\": \"iVBORw0KGgoAAAANSUhEUgAAAYAAAAEWCAYAAABv+EDhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvNElEQVR4nO2debxeVXX3vz8QVBQIkMgMUcG2aOEKaQLUKkpfRWoBW8WpClql1pKbGHwr1Uou+rZFrQGiLf2goGARoXWAIg7I5FCIJDGE0RItyDwHUFFM7nr/2Odwzz155vvMz+/7+ZzP85x9hr3Ofc7da++11l5bEYExxpjRY7NeC2CMMaY3WAEYY8yIYgVgjDEjihWAMcaMKFYAxhgzolgBGGPMiGIFYJpG0h9Kuk3SLyQdJembko7ptVz9hKSQtFeL175N0nfaLVMvkXSTpEN6LYeZjjwPYDSQdDuwI7AR+CXwTeD4iPhFC/e6HLg4Ik6vcOxY4N0R8bIZCdwmskbnCuBXQAD3AKdExOc7XG8Ae0fEujrnzQX+F9giIjZ0UqZ+QdIEsFdE/EWvZRl1PAIYLf40Ip4L7A/MA/6+fIKkZzRwnz2Bm9osWye5J3vubYAPAp+VtE+PZRpoGnxPTJ9jBTCCRMTdpBHAS+Bpc8XfSLoNuC0re4+kdZIekXSxpF2y8p8CLwD+KzMBPVPSVZLeLen3gH8DDsqOrc+uOVzSzZKekHS3pA+UZcrus17SSwplcyQ9Kel5kmZLuiQ75xFJ35fU1Psbia8DjwL7ZHWeJumebDtN0jOzug+RdJekD0l6SNLtkt5WkO0qSe8u7B8r6QeV6pX0J5J+LOlxSXdmPeCc72Wf67O/2UHle0k6WNJ1kh7LPg8uyfExST/M/r7fkTS7ihz1numZkv5Z0s8l3S/p3yQ9u3TtByXdB1QcQWXvzS2ZLDdL2j8rv13SH0s6DPgQ8Kbsea+X9EZJq0r3WSLpokp1mPZhBTCCSNodOBz4caH4KGABqWF8FfBPwNHAzsAdwJcBIuKFwM/JRhMR8Zv8BhFxC/Be4Jrs2Kzs0FnAX0XE1iSlc0VZpuw+XwXeUig+Grg6Ih4ATgDuAuaQTFkfIpl0mnnuzSS9HpgF3AB8GDgQGAP2A+YzfVS0EzAb2BU4BjhT0u80U2fGL4F3ZPX+CfDXko7Kjr08+5yV/c2uKcm8PfANYDmwA7AM+IakHQqnvRV4J/A8YEtgEwXb4DOdAryI9PfYKzvnpNK125NGgMeVbyzpjcBE9qzbAEcADxfPiYhvAf8IXJA9737AxcDzsw5EztuBc2s8h2kDVgCjxdezXvkPgKtJ/4g5/xQRj0TEk8DbgLMjYnXWMP8dqVc/t8V6f0tSLNtExKMRsbrKeV8C3lzYf2tWlt9jZ2DPiPhtRHw/Gndg7ZI990PAUuDtEfET0nN+NCIeiIgHgZNJDU+Rj0TEbyLialJDfHSDdT5NRFwVETdExGRErAXOB17R4OV/AtwWEV+MiA0RcT5wK/CnhXM+HxH/k/12F5Ia8Fps8kySRGrU35+9B0+Q3o/i7zEJLM2ufbLCfd8NfCIirstGW+si4o56D5i9YxcAfwEg6cXAXOCSeteamWEFMFocFRGzImLPiHhf6Z/4zsL3XUi9fgAyR/HDpB5hK/w5acRxh6SrJR1U5bwrga0kLciUzRjwtezYJ4F1wHck/UzSiU3Uf0/23NtHxFhEfDkrn/ac2fddCvuPRsQvaxxviOx5rpT0oKTHSKOkimaaCpRlzOUo/hb3Fb7/CnhujftVe6Y5wFbAqszMth74Vlae82BE/LrGvXcHflrjeC3OAd6aKaK3AxcWR5emM1gBmJxib/oe0jAfAEnPIZkf7m7yPqkg9QiPJJkovk7qpW56YcTG7Nhbsu2SrCdKRDwRESdExAtIpoUlkg5tQJ5aTHtOYI+sLGe77NkrHf8lqcHM2alGPV8imTl2j4htSX4SZcfqjWLKMuZyNPJbVKLaMz0EPAm8OFOWsyJi28x5nlNP1juBFzYgQ6V35FrgKeCPSCO/LzZwHzNDrABMJc4H3ilpLHOK/iOwIiJub+Da+4HdJG0JIGlLpbj2bSPit8DjJFNCNb4EvIlknsnNP0h6naS9sh7iY6Rw1lr3aYTzgb9XcjbPJtm7/710zsnZM/wR8DrgP7LyNcCfSdpKKd7/L2vUszXwSET8WtJ8UgOX82D2HC+ocu2lwIskvVXSMyS9CdiHmZlHNnmmiJgEPgucKul5AJJ2lfSaJu77OeADkg5QYi9JZeUF6R2Zq02d+OcCnwF+GxEVHeqmvVgBmE2IiO8CHwG+AtxL6tW9ueZFU1xBChG9T9JDWdnbgdslPU4yf7yt2sURsYLUu96FFKmUszfwXeAXwDXAv0bElQBKE9E+1KB8Rf4fsBJYS3IKr87Kcu4jRQzdA5wHvDcibs2OnUrqsd5PMl+cV6Oe9wEflfQESck8PQKKiF8B/wD8MDO9HFi8MCIeJjXSJ5DMcH8LvC4iHqI1aj3TB0lmtmuz3+q7QMNO74j4j+xZvgQ8QRrtbV/h1FyJPiyp6A/6IilIoKyETYfwRDBjKqA0gezfI2K3HovSNvr9mbKQ0weA/SPitl7LMwp4BGCM6Rf+GrjOjX/38Gw+Y0zPUUpVItJ8FNMlbAIyxpgRxSYgY4wZUQbCBDR79uyYO3dur8UwxpiBYtWqVQ9FxJxqxzumALJ8M+eS8rYEcGZEnK6UCOs9pPhngA9FxKW17jV37lxWrlzZKVGNMWYokVQzFUcnRwAbgBMiYrWkrUlTzC/Ljp0aEf/cwbqNMcbUoWMKICLuJU0iIiKekHQLreeSMcYY02a64gTOEnu9FFiRFR0vaa2ksyVtV+Wa4yStlLTywQcfrHSKMcaYGdBxBSDpuaSUAosj4nHgDFJqgTHSCOFTla6LiDMjYl5EzJszp6oPwxhjTIt0VAFI2oLU+J8XEV8FiIj7I2JjIfnU/E7KYIwxA0l5jlYH5mx1TAFkWRvPAm6JiGWF8p0Lp70euLFTMhhjzEAyMQHvf/9Uox+R9icm2lpNJ0cAf0jKAvkqSWuy7XDgE5JukLQWeCXw/g7KYIwxg0UErF8Pp58+pQTe//60v359W0cCnYwC+gFTi14UqRnzb4wxI40Ep56avp9+etoAFi1K5arUrLZY1SDkApo3b154IpgxZqSIgM0KRprJyaYbf0mrImJetePOBWSMMf1GbvYpUvQJtAkrAGOM6SeKNv9Fi1LPf9Gi6T6BNjEQyeCMMWZkkGDWrOk2/9wnMGuWfQDGGDP0RExv7Mv7DWAfgDHGDCLlxr6NPf8cKwBjjBlRrACMMYNFF1IkjApWAMaYwaFLKRJGBSsAY8xg0MUUCaOCw0CNMYNBF1MkjAoOAzXGDBZtSJEwKjgM1BgzPHQpRcKoYAVgjBkMupgiYVSwD8AYMxh0I0VCG2bfDhL2ARhjBotONdITEymaKFcu+Yhj1qyBDTO1D8AYM1x0IkXCiIaY2gRkjDEjGmJqE5AxxuQMWYipTUDGGNMItUJMB6Cj3Ao2ARljTNHmv2BB2iDt543/dtsNrDO4Gh4BGGNMHmI6Pp4a/+XLU/n4OKxYkfaH0BnsEYAxxkDq3ecNvDTlCIahdQbbCWyMMWWGxBlsJ7AxxjTDCOUbsgIwxpicEcs3ZB+AMcbkdCPfUB9hH4AxxpQZkqRwPfMBSNpd0pWSbpZ0k6RFWfn2ki6TdFv2uV2nZDDGmJboRL6hPqSTPoANwAkRsQ9wIPA3kvYBTgQuj4i9gcuzfWOMMV2mYwogIu6NiNXZ9yeAW4BdgSOBc7LTzgGO6pQMxhhjqtOVKCBJc4GXAiuAHSPi3uzQfcCOVa45TtJKSSsffPDBbohpjDEjRccVgKTnAl8BFkfE48VjkTzQFb3QEXFmRMyLiHlz5szptJjGGDNydFQBSNqC1PifFxFfzYrvl7Rzdnxn4IFOymCMMaYynYwCEnAWcEtELCscuhg4Jvt+DHBRp2QwxhhTnU5OBPtD4O3ADZLWZGUfAk4BLpT0l8AdwNEdlMEYY0wVOqYAIuIHQLXg2UM7Va8xxpjGcC4gY4wZUawAjDFmRLECMMaYEcUKwBhjRhQrAGOMGVGsAIwxpt2U0+z3adp9KwBjjGknExPTVw/LVxmbmOilVBWxAjDGmHYRAevXT19CMl9icv36vhsJeEnIRhiS1YGMMR2muITk6aenDaYvMdlHeARQjwEazhlj+oCiEsjpw8YfrABqM2DDOWNMH5C3E0WKncg+wgqgFrkmX7QoNfqbbZY++3Q4Z4zpMcVO4qJFMDk51X70oRKwAqjHAA3njBkJ+jnEUoJZs6Z3EvNO5KxZfddu2Alcj2rDOSsBY7rPxEQyv+b/f/n/56xZ/eOXm5iYHiiSK4E+bC88AqjFgA3njBlqBsknV27s+7DxB48AalNtOAd9OZwzZqgZsBDLQUDRT1qzCvPmzYuVK1f2TgDPAzCmf4hIARk5k5P+f6yCpFURMa/acZuAGmFAhnPGDD0DFGI5CFgBGGMGA/vk2o59AMaYwcA+ubZjH4AxZrCwT65h7AMwxgwX9sm1DSsAY4wZUWoqAEnbSjpF0q2SHpH0sKRbsrJZXZLRmMGln9MWmJGn3gjgQuBR4JCI2D4idgBemZVd2GnhjBlonErc9Dn1FMDciPh4RNyXF0TEfRHxcWDPzopmzAAzSGkLzMhSLwz0Dkl/C5wTEfcDSNoROBa4s8OyGTO4OG2BGQDqjQDeBOwAXC3pUUmPAlcB2wNH17pQ0tmSHpB0Y6FsQtLdktZk2+EzlN+Y/sWpxE2fU1MBRMSjEfHBiPjdiNgu234vK3ukzr2/ABxWofzUiBjLtktbFdyYvsdpC0yfUzcMVNJrJJ0h6eJsO0NSpYZ9GhHxPaCekjCmf5lJBI/TFpgBoKYPQNJpwIuAc4G7suLdgHFJr42IRS3UebykdwArgRMi4tEW7mFMZ5npwiNOW2AGgHpO4MMj4kXlQkkXAP8DNKsAzgA+BkT2+SngXZVOlHQccBzAHnvs0WQ1xsyAYgQPpIa72JtvNPXAAK0MZUaTegrg15L+ICKuK5X/AfDrZivLI4kAJH0WuKTGuWcCZ0LKBdRsXca0TDsjeJy2wPQx9RTAscAZkrZmygS0O/BYdqwpJO0cEfdmu68Hbqx1vjE9I1cCeeMP7r2boaOmAoiI1cACSTsBu2bFdxcnhlVD0vnAIcBsSXcBS4FDJI2RTEC3A3/VsuTGdJJqETxWAmaIqLsegKRtgVdQUACSvh0R62tdFxFvqVB8VtMSGtNtyhE8RR8AWAmYoaFeMrh3AKtJPfmtsu2VwKrsmOk3nHxs5lSL4Fm0yBE8ZqiouSCMpJ8AC8q9fUnbASsqRQh1Ai8I0yAzDV000/HCI2bAmemCMCLZ68tMZsdMv+DkY61Ra8TkCB4z5NTzAfwDsFrSd5hK/rYH8H9IcfymX3DysebxiMmMOPVyAZ0DzAOuBn6TbVcB8yLiC50WzjSJk481jkdMxtSPAspSNXy5C7KYmeLQxcbxiMmY1tYElvRdSd+U9Lp2C2RaxMnHmscjJjPi1B0BVOEdwM7AgW2UxcwEJx9rHo+YzIjTsAKQtD1ARDwSEfcA9wCrOiWYaQEnH2scT/Yypm466D2ATwCHAutTkbYBrgBOjIjbOy2gaRKHLjaGR0zG1J0Idg1wGvCfEbExK9sceCOwOCK6YgLyRDDTMTzZywwxM50INjsiLsgbf4CI2BgRXyatFWzMYOMRkxlh6vkAVkn6V+AcpiaC7Q4cA/y4k4KZLuJecH/h38N0iXojgHcANwAnA9/OtglSHv+3d1Qy0zrNJISbmJgeJpo7Rz0Ttjf49zBdpN5M4Kci4oyIOCwifj/bXhsR/xoRv+mWkANPNzJ05vfMG5DJyanyag2IZ8P2F/49TJdpdR4Akk6KiI+2U5ihpBv5ZvI6li2bakCuvhqOOAIee6z6WraeDdtf+Pcw3SYiWtqAn7d6bbPbAQccEAPJ5GTEokURkD4r7be7jo0bI8bG0n6+1atrcnL6+e2Qy7SOfw/TJoCVUasdr3kQHq+yPQFsqHVtO7eBVQAR0xvoRhvkdtTRaAPSDflM4/j3MG1kpgrg58COVY7dWevadm4DrQAiutOjK9fRSAPSjRGKaRz/HqbN1FMA9XwA5wJ7AvdXOPalGVqfRoPoQr6ZSnWMjcGqVbBkSfX0Bp4N21/49zDdppZ26JdtYEcAvfABnHTSlA8g9wksWhSxdGnte9TaN93Fv4dpE8xwBLAJWX6grSLi1varoyGjGz26SnUsXZp6/rNmwWab1R9teDZsf+Hfw3SJmrmAACSdApwbETdL+nNgGSkx3CUR8eHOizgEuYCiCzM7u1GHMWagmGkuIIDDIuLm7Pv7gVcD+wNeDKZRutGjc6/RGNMk9dJBLwV2lHQS8GzghcCbAAHbZuVXRcT3Oi6pMcaYtlJTAUTEyZL2IUUCbUMyBX1U0pbAq8MzgY0xZmBpxAn8LlJSuKdIYaEAewD/1CmhjDHGdJ66CiAifgmcUSpbB6zrlFDGdBU70M2I0ogTuCUknS3pAUk3Fsq2l3SZpNuyz+06Vb8xDeH0y2aE6ZgCAL4AHFYqOxG4PCL2Bi7P9o3pDeH0y2a0aTkddD0i4nuS5paKjwQOyb6fA1wFfLBTMhhTE6dfNiNO3YlgAJLmAO8B5lJQGhHxrjrXzSVNGHtJtr8+ImZl3wU8mu9XuPY44DiAPfbY44A77rijrpzGtEREmjGdMznpxt8MBe2YCAZwEbAt8F3gG4WtZbI8FVW1T0ScGRHzImLenDlzZlKVMdWplqzP5h8zAjRqAtoqItphqrlf0s4Rca+knYEH2nBPY1qjaPPPzT75PtgMZIaeRhXAJZIOj4hLZ1jfxcAxwCnZ50UzvN/McPjfaNNMsj6/K2YIadQH8ATwHOA3wG9JqSAiIrapcc35JIfvbNJ6AkuBrwMXkiaS3QEcHRGP1Ku/I8ngurFWrxkM6jXuflfMgFLPB9DQCCAitm624oh4S5VDhzZ7r7ZTDP+D6UP/Sounm+GmViI9vytmiKk5ApD0uxFxq6T9Kx2PiNUdk6xAR0YARftvjsP/TCX8rpgBpd4IoJ4CODMijpN0ZYXDERGvaoeQ9ejYegAO/zON4nfFDCAzCgONiOOyz1dW2LrS+HcMh/+ZRvG7YoaUTqaC6F/K4X+Tk+mzmBLAGPC7YoaajqWC6Gu6sVavGQ78rpghpqEw0F7TUR+AY7sHi179Zn5XzADSllQQki5vpGzg8Dq6g0UvUzf7XTFDSE0FIOlZkrYHZkvaLsvnv32W5G3XrkhoBoPySLLdI0unbjam7dTzAfwVsBjYBSjG/D8OfKZDMplBoxszZZ262Zi2Uy8M9PSIeD7wgYh4fmHbLyKsAEaJaj38bvbMi0ogx42/MS1TcwQg6VURcQVwt6Q/Kx+PiK92TDLTP9Tr4XerZ14tHt9KwJiWqOcEfnn2+acVttd1UK7e0ml7difolMyN9PC70TN3PL4xbaeeD+DR7POsiPhBp4XpCwYx82MnZW7E9t5qz7yZ0ErH4xvTfiKi6gasyT5X1zqv09sBBxwQXWFyMmLRoghIn5X2+41uyTw5me6Zb/l9W61/6dLpx/Prli6tL0etfWPM0wAro0bbWm8EcIuk24BdJK0tlOfrAezbEa3UK/JeZcT03u74eHfszK1MNpppdEwjddbr4ec982XLpsuz7baV659JimXH4xvTPmpph6RA2Am4HtizvNW7tl1b10YAEakHOj4+vbc7Pl6/Z9qOeiv1iE86afp51Xq81XrordRZfNZGeviTk0nO4v7GjbV79MX75Fu/jrKMGVCoMwKoOxM4Iu6LiP2Ae4Gts+2eiLijQzqpd0TAo4/C8uXTy5cvT+WVHI3lslackcUecdnRevHFyeGZn1ec+ZrXVa2HXkuWWnUWwzer2d4XLUrlJ58MixdP3Wvx4rQdfHDtUFCHdBrTe2pph3wDXkFawvFq4HvA/wIvb+Tadmxd9QGUe//FUUC5d9qqHbta3eUe8dhY9Z533uPOe9r5+Xl5Iz3qZnrhlWzvxevHxyuPnGqNWDwCMKajUGcE0KgCWAX8TmH/RcCqRq5tx9aXJqBOOF/LZpxi415sJIvluTIoKot65pdadTYrd6WGvN69BtHZbswA0i4FsLaRsk5tXVUAlUYB1Xqy7ezFVrvXxo2VG9V6dTciQ7vkLyuRRu7VztGTMaYi7VIAnwc+BxySbZ8Fzm7k2nZsfR0GWis8sh315j37ao18q733dvXCqynMvKzWvRzSaUxHqacAGl0R7L3AzcB4tt0M/HXrnoc+pZ7Ds9HwyMnJ5tIUV6p32TIYG4M1ayrPfM3rKNcdNRy/M3nWSuTPv3w5LFiQwmXHx6ec6OPjte/lkE5jekst7ZAUCJsDt9Y7r5NbSyOAmfQuG7m2Ui+9/NmsOaV8bjG0slhn0dGbm6fK+63W2WwvvGjKKTqGly51j96YHkOdEUBDK4JJughYGBE/76w6qkzTK4J1K51DXs+yZbBkydTEJmhfMrSIyhO1JibgW99KPe/TTkvHFi+GFSvgsMO6m7aimozGmJ7SlhXBgO2AmyRdLunifGuPiG0mojvpiSOmMmFutllSAkXKjX+53mZMNZX2ly5Njf/y5dNNQStWzPw5m5W126acVv+WxphpNLoo/Ec6KkU76cbCIRMTaWLYaael+23cCPNKSraYKqETIxJpqv52Pme/J8Prd/mMGSRq2YeAZ5FWBPsMaXWwZ9Q6v1Nbyz6AcoRMO2zSk5MRCxZM2dtPOili9uy0v9NOERs2VI7J71TMeyORQI3a+fs9Pr/f5TOmz2AmYaDABcC/Z43/14HTa53fqa1pBVBspMuhiTONMz/ppIj99pt+73w7/vip8Md8Vm4uz0xm3NZ6znr3bTbevt9n6Pa7fMb0ETNVADcUvj+DNqWFBm4HbgDW1BMwmlUA5bj0coqCZqNkyvfOG59qSqDY8y9fW62nnn9vprFuNElbKz3mmc4O7jT9Lp8xfcJMFcDqWvutbpkCmN3o+U2PAPJ0DuUJSgsWtMfkUi1fULUGqVKvNVdElUI7G22sm83m2UiPud972P0unzF9xEwVwEbg8Wx7AthQ+P54rWvr3LezCiBiqnFtpKfYrNmlngKo1ChXG40UZ8xWy/1TT556sjfzd+hnG3u/y2dMnzEjBdCpjZRNdDUpydxxVc45DlgJrNxjjz2af/JGe4rN2sg3bozYccfKDf/8+ZVTIJQnS5UVSCPpHVqdsNVsj7nfc/T0u3zG9BH9qgB2zT6fR1ps5uW1zm/JCdxIT7HZHmXZB7Bx45Szed99kxmnWoNUtvmXG/myzb7YWFebEdzI8omt+gBq7feafpfPmD6hngJodB5AW4mIu7PPByR9DZhPWmegPTSygHhE83MGyssfbrYZXHNNmoGbL44C1a9ND71pDp+DDoL589M5y5enHDqQJnWdfvpUTqD83rWWTyzuS2lZxmYXUu/3HD39Lp8xA0JDqSDaWqH0HGCziHgi+34Z8NGI+Fa1a5pOBZFTrXEsTyaanITNN586b3KydqNSq9GtJ0+x8T711NT4r1iRju+yCzzvean+tWth4UL4/vdhm23gpS+tnmqi2nPl9W277ZRyakZeY8xA065UEO1kR+AHkq4HfgR8o1bjPyMq9RQjpqeKmJyEAw6Yfl69rJqN9kAr3aM4MolI6RwgNfz33JN6+mvXwn77pfuuWZMa/3KqiXwB9ryRX7q0egqMxx6bLku1hdrryW6MGS5q2Yf6ZWt5PYBqtuJKtvaxscqzdlullrNycnLq+MaNtaOKqkUHVZK3lSiierIaYwYW+tEJ3OzWkgKo16iVHbH5xK1mGr9GFEwl52u54d6woboC+MhHNr22nYvEOLTSmKFlNBVArUZtfLx+T7mRRq8RBVOvjvLxStvY2JQSyK9tdZnIRv5ezVxnjOlrRlMBRFRu1BYsiFi4cMrkMj6e9vNQzkopHOrdu16Yaa3eeLkhL/fsd9ppU7mqNdYzTTrn9ArGDB31FEAvnMDdoRjymLNgAXz60ynqZnwcrr027c+fn/a33TYt7DIxUd8JnC+fePrpKRy0GNlTdM4WyZ2z+bZkyfTjW245ff/uu6eWaNxss02jiIrLRC5ZUjnks5ElHmvJaowZXmpph37Z2jYCqJQfqNrIIE/1XL5nkUZMMeXe+IIF0+XIv8+fv6lclUYkjZieaslc6+9kH4AxQwUjaQKq5wOoZXYZG5tqjIspncsNbz1nbKWGenx8ytxUVgT5vfKEdfVmJNfabxZHARkzlIymAoiYyghabNSK9v56W57uuZJ9vdj41wofrdRQ10r3UJa3m42w0ysYM3TUUwBdnwncCi3NBC4v25hP+FqzZspOvmhR8gFUo5JNvzgbd2wMVq2abp9vZGnCiHRNTj7zOMKLqxtj2kY/zgTuPBFpVmy+YHpkDtc1a1Kjnc+qrde45rNt83PLTuW88S8eb6Txr+ZwdY4bY0wXGU4FUCtKJ2+088RuY2PV77P//ql3DpUb7iVLpo7n9daiOIooR/E46sYY02WGUwFA5R77qadO9dgjUo6cNWtSeOiOO06dNz4O++4L118PBx+cGuq84R4bg40bpxruAw5IeXgalalSltJGQjWNMabNDK8CqGVqgemN8X//N8ydm8rHxlL5IYdMXZenVc7TMi9ZksxD+X452VotJiamp4tu1HRkjDHtppaHuF+2GYWB5pE15f3iuflnOUS0fG6rydaMMaYHMJIzgfPefZ5qGVIve+HCNAs4z41fdLxKKWKoSB5BlLPZZpXNSjbdGGMGkOFUAJDs8gsWTEUCTUzA976XFMD69cmuv3jxlOklt/MXydcLyM079cxKxhgzQPRkSciukPfopU1j95ctSw338uVJSUxOwn/9V7Ln77QTvOEN8IMfpOuuvjrl6DnssGTrL+b8Kc4L8EjAGDNgDO9EsJzypKsyCxdOrcU7ezY89NDUseL++HgyKz322KaTwxqZ/GWMMV2m3kSw4R0BQGWTTZHx8Sm7f3mkANMb/3w0UVSYlUJNjTFmQBheH0B50tXGjdUnfdVryIvO4ImJTe3+uY/BGGMGiOFVAMU4/9zmv2bN9HOWL0+O4EoO4CKLFqUGf3ISLr648sLr69fXdwaXjw+A+c0YM7yMhg8A4KCDUgTQwoWpwV68OCmA+fPhwAPT9/32S7N/c4o+gIUL0+enPz01ASynOLO3GhMTSUnYf2CM6RKj7QOAqUb5sMNSxE9uzlmzBnbYAV7zmuQkHh+HCy6ArbeGY4+FH/0oNdK77pqUQp41dMGCNHN4882n6qjX+OfJ6YoRQ0XzlLN+GmN6Qa1ZYv2ytbQeQCUqLeYyNhaxYcNU/v+xsYinnpq+Yle9VcUaWUvYC68bY7oMI7seQE65d503vzC1PkDO2BisXAknnJBy/+QppYvkZqJ8LYAlS6aSxB1xxNQs42qyVFoHwBhjOsBorgeQU47YiYDdd09mHUiNfZHrrkuNf+7ULaZ6hmQmuv765BtoNimcZxEbY/qM4fUBVLK7L1oEd9+d9vfff9NrttgifS5aBJ/6FOy226bnjI+n0cHjj6d75/cvrx5WHnUUbf6eRWyM6Qdq2Yf6ZWvZB1DJ7r5wYcS++04vK+8/9VT1NX/zDKGTk9OvyX0A1dby7dTC617L1xhTBer4AIZ3BABTefyLnHZaCgFdu3aq7BWvmL6/5Zbps7jmbz5RbNas9Fk25xxwwHSfQDm6Z2Ji0+yjM+35O7TUGDMTammHTm3AYcBPgHXAifXOb3kEUIz2ybc82qe8VSrfsGH6/fKefz4ayKN/ynV0I7qnLEelfWPMSEOdEUAvGv/NgZ8CLwC2BK4H9ql1TUsKoNgglhvovMFfuLC2EqjWkJbNORs3Tr+uW42vQ0uNMTWopwB6EQU0H1gXET+LiKeALwNHtr2WYiqIVaumH9txR1i9etPkb9dfP5U3qNZi7cVlHSOS2adIt6J7qq17bIeyMaYBeqEAdgXuLOzflZVNQ9JxklZKWvnggw+2VtPERArTLDfQRx+dPst2/HytgNzmX2ux9qLNPbf5T07WVhztJq+/iENLjTEN0rfzACLizIiYFxHz5syZ0+pNpjtl8wb6059OTttyeR7bH9HYYu3FUUbe866nONpFr5WPMWbg6UUU0N3A7oX93bKy9pM30OPj0xvoiClzT7EcpjfcjTTgnYjuaYRqygc6r3yMMUNBLxTAdcDekp5PavjfDLy161IcckhaN7gdDXf5mm41vr1SPsaYoaDrJqCI2AAcD3wbuAW4MCJu6lBlU/l8ivn7ly9P5WUGseHslfIxxgw8PZkIFhGXApd2vKKiWaSctmHZMjeWxpiRpm+dwG2j0mzgPDLIs2WNMSPM8CuAfBnHInkEUCPLOFajfJ2jbowxA8ZwK4A8DHTNmukLwuf7rZqBKqWZ9sLwxpgBY7gVQK3ZwEccMX1xlkbJHcutLgxvjDF9wnBnA4XUK5+c3HQ2cL54S7MjgFqOZYdgGmMGiOEeAUD12cAzmTHrHDzGmCFg+BVAJ9I1OAePMWYIGH4TELR3xmw5B4+XdzTGDCijoQCgfTNmnYPHGDMkKAbAbDFv3rxYuXJlr8WYTtmB3IpD2RhjOoikVRExr9rx4fUBdHqilnPwGGMGnOFUAJ6oZYwxdRk+BeCJWsYY0xDD5wT2RC1jjGmI4XUCR0xP9TA56cbfGDNSjKYT2BO1jDGmLsOnALxYujHGNMRw+gA8UcsYY+oy3D4AT9Qyxowwo+kDAE/UMsaYOgyvAjDGGFMTKwBjjBlRrACMMWZEsQIwxpgRZSCigCQ9CNzR4uWzgYfaKE6nsbydZ9BktrydZdDkhcZl3jMi5lQ7OBAKYCZIWlkrDKrfsLydZ9BktrydZdDkhfbJbBOQMcaMKFYAxhgzooyCAjiz1wI0ieXtPIMms+XtLIMmL7RJ5qH3ARhjjKnMKIwAjDHGVMAKwBhjRpShUQCSbpd0g6Q1kjZJHarEcknrJK2VtH8v5Mxk+Z1Mznx7XNLi0jmHSHqscM5JXZbxbEkPSLqxULa9pMsk3ZZ9blfl2mOyc26TdEyPZf6kpFuz3/xrkmZVubbm+9NFeSck3V343Q+vcu1hkn6Svc8n9lDeCwqy3i5pTZVre/H33V3SlZJulnSTpEVZeV++xzXk7dw7HBFDsQG3A7NrHD8c+CYg4EBgRa9lzuTaHLiPNGGjWH4IcEkP5Xo5sD9wY6HsE8CJ2fcTgY9XuG574GfZ53bZ9+16KPOrgWdk3z9eSeZG3p8uyjsBfKCBd+anwAuALYHrgX16IW/p+KeAk/ro77szsH/2fWvgf4B9+vU9riFvx97hoRkBNMCRwLmRuBaYJWnnXgsFHAr8NCJanencESLie8AjpeIjgXOy7+cAR1W49DXAZRHxSEQ8ClwGHNYpOYtUkjkivhMRG7Lda4HduiFLI1T5GzfCfGBdRPwsIp4Cvkz6bTpKLXklCTgaOL/TcjRKRNwbEauz708AtwC70qfvcTV5O/kOD5MCCOA7klZJOq7C8V2BOwv7d2VlvebNVP+nOUjS9ZK+KenF3RSqCjtGxL3Z9/uAHSuc069/Z4B3kUaBlaj3/nST47Ph/tlVzBP9+Df+I+D+iLityvGe/n0lzQVeCqxgAN7jkrxF2voOD9OSkC+LiLslPQ+4TNKtWY+lb5G0JXAE8HcVDq8mmYV+kdmBvw7s3UXxahIRIWlgYoglfRjYAJxX5ZR+eX/OAD5G+mf+GMms8q4eyNEsb6F2779nf19JzwW+AiyOiMdVWByqH9/jsryF8ra/w0MzAoiIu7PPB4CvkYbJRe4Gdi/s75aV9ZLXAqsj4v7ygYh4PCJ+kX2/FNhC0uxuC1ji/txsln0+UOGcvvs7SzoWeB3wtsiMpWUaeH+6QkTcHxEbI2IS+GwVOfrqbyzpGcCfARdUO6dXf19JW5Aa0/Mi4qtZcd++x1Xk7dg7PBQKQNJzJG2dfyc5TW4snXYx8A4lDgQeKwwDe0XVXpOknTK7KpLmk36rh7soWyUuBvJoiGOAiyqc823g1ZK2y8wXr87KeoKkw4C/BY6IiF9VOaeR96crlPxSr68ix3XA3pKen40i30z6bXrFHwO3RsRdlQ726u+b/f+cBdwSEcsKh/ryPa4mb0ff4U56tbu1kaIhrs+2m4APZ+XvBd6bfRfwL6ToiRuAeT2W+TmkBn3bQllR3uOzZ7me5Pg5uMvynQ/cC/yWZP/8S2AH4HLgNuC7wPbZufOAzxWufRewLtve2WOZ15FsuWuy7d+yc3cBLq31/vRI3i9m7+daUkO1c1nebP9wUpTIT3spb1b+hfy9LZzbD3/fl5FMaWsLv//h/foe15C3Y++wU0EYY8yIMhQmIGOMMc1jBWCMMSOKFYAxxowoVgDGGDOiWAEYY8yIYgVgGkLSxizL4I2S/kPSVm2+/1WSai5yLWlxsV5Jl1bLjNgmmeZIWiHpx5L+qHRsC0mnZJkiV0u6RtJri3Jl2/uarHMXSf/Z5DXHK2UFjeJkwWzOS90MuKqSWTSbZ7AiK78gm3OApGdm++uy43Obkdf0D1YAplGejIixiHgJ8BRpzkK3WQw8rQAi4vCIWN/B+g4FboiIl0bE90vHPkbK3viSiNiflFBs65Jcs4CmFEBE3BMRb2hSzh+SJmOVEwq+lpQ+ZG/gOFKaiWlI2pw0P+a1pMyTb5G0T3b448CpEbEX8ChpngLZ56NZ+anZeWYAsQIwrfB9YC+lvOpfz3qX10raF57Oaf/FrFd8m6T3ZOWHSLokv4mkz2RT3Kch6QxJK5Vyop+clY2TJr5cKenKrOz2vMcraUk2OrlR2doKkuZKukXSZ7N7fUfSsyvUN1fSFdlzXC5pD0ljpLTBR2Yjn2cXzt8KeA+wMCJ+A0+ncLiwJNcpwAuz6z8p6VxJRxXuc56kaVk8M1luzL4fK+mrkr6V/R0/UenHiIgfR8TtFQ41kgG3YmbRbFbqq4B8NFLMmlnMpvmfwKHZaOPFkn6UPe9aSX2Tu8pUxgrANIVS3pfXkmarngz8OCL2BT4EnFs4dV9SA3IQcJKkXZqo5sMRMS+7xysk7RsRy4F7gFdGxCtLMh0AvBNYQFrr4T2SXpod3hv4l4h4MbAe+PMK9X0aOCd7jvOA5RGxBjgJuCAb+TxZOH8v4OdRSNRVhRNJqb7HIuL/kqb5H5vJvC1wMPCNOvcYA94E/D7wJkm71z59Go1ktKx2zg7A+phKQ1y89ulrsuOPZee/Fzg9IsZIs2orpoYw/YMVgGmUZyut9rQS+DmpMXsZKXUBEXEFsIOkbbLzL4qIJyPiIeBKmkv+dbSk1cCPgReTTBO1eBnwtYj4ZaQEel8lpScG+N+sMQdYBcytcP1BwJey71/M7td2IuJqUg6fOaQ8UF8pNLDVuDwiHouIXwM3A3t2QrY2cQ3wIUkfJGWyfbLeBaa3WAGYRsl9AGMRsTAzF9SinGMkSKlsi+/cs8oXSXo+8AHg0KxH/o1K5zXBbwrfN9KeFOjrgD0Kyq4ZzgX+gjRiObuB82cifyMZLaud8zDJZPSMCtc+fU12fFvg4Yj4Eim9+ZPApZJe1YSspgdYAZiZ8H3gbZDs+8BDBbPIkZKeJWkH0vKW15GclPtkUSSzSE7WMtsAvwQek7QjydyU8wSZo7WCHEdJ2kopE+Lrs7JG+W9SRk2y56l5baSMjGcBpxciY+ZIemPp1EryfoHkzCYibm5CxlaomgFX0q3ZORUzi0ZKEnYlkDuki1kzi9k03wBcEREh6QXAzzJz3UUkE57pY6wAzEyYAA6QtJbk8CwunL2W1IBcC3wsi265E7iQlKb2QpKJZxoRcX1WfivJLPPDwuEzgW/lTuDCNatJDeuPSCsofS4iNrl3DRYC78ye4+3Aogau+XvgQeDmzGl7CTDNJxARDwM/zBzTn8zK7ict9ff5JuSriaRxSXeReulrJX0uO3QpaS3bdaS1Bd6XnT+blB03t+EfT0p1fAtwYUTclF3/QWCJpHUkG/9ZWflZJHPfOmAJydcBaUnIGzNT4UuY7hMyfYizgZq2I2kC+EVE/HOvZek3sgiiG0iLfz/WIxleB7wg66mbEWaYloQ0pq+R9Mek3vOpvWr8ASLikvpnmVHAIwBjjBlR7AMwxpgRxQrAGGNGFCsAY4wZUawAjDFmRLECMMaYEeX/AytMvVQB4LocAAAAAElFTkSuQmCC\\n\",\n",
    "      \"text/plain\": [\n",
    "       \"<Figure size 432x288 with 1 Axes>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {\n",
    "      \"needs_background\": \"light\"\n",
    "     },\n",
    "     \"output_type\": \"display_data\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Create a scatter plot of the data. To change the markers to red \\\"x\\\",\\n\",\n",
    "    \"# we used the 'marker' and 'c' parameters\\n\",\n",
    "    \"plt.scatter(x_train, y_train, marker='x', c='r') \\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set the title\\n\",\n",
    "    \"plt.title(\\\"Profits vs. Population per city\\\")\\n\",\n",
    "    \"# Set the y-axis label\\n\",\n",
    "    \"plt.ylabel('Profit in $10,000')\\n\",\n",
    "    \"# Set the x-axis label\\n\",\n",
    "    \"plt.xlabel('Population of City in 10,000s')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Your goal is to build a linear regression model to fit this data.\\n\",\n",
    "    \"- With this model, you can then input a new city's population, and have the model estimate your restaurant's potential monthly profits for that city.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"<a name=\\\"4\\\"></a>\\n\",\n",
    "    \"## 4 - Refresher on linear regression\\n\",\n",
    "    \"\\n\",\n",
    "    \"In this practice lab, you will fit the linear regression parameters $(w,b)$ to your dataset.\\n\",\n",
    "    \"- The model function for linear regression, which is a function that maps from `x` (city population) to `y` (your restaurant's monthly profit for that city) is represented as \\n\",\n",
    "    \"    $$f_{w,b}(x) = wx + b$$\\n\",\n",
    "    \"    \\n\",\n",
    "    \"\\n\",\n",
    "    \"- To train a linear regression model, you want to find the best $(w,b)$ parameters that fit your dataset.  \\n\",\n",
    "    \"\\n\",\n",
    "    \"    - To compare how one choice of $(w,b)$ is better or worse than another choice, you can evaluate it with a cost function $J(w,b)$\\n\",\n",
    "    \"      - $J$ is a function of $(w,b)$. That is, the value of the cost $J(w,b)$ depends on the value of $(w,b)$.\\n\",\n",
    "    \"  \\n\",\n",
    "    \"    - The choice of $(w,b)$ that fits your data the best is the one that has the smallest cost $J(w,b)$.\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"- To find the values $(w,b)$ that gets the smallest possible cost $J(w,b)$, you can use a method called **gradient descent**. \\n\",\n",
    "    \"  - With each step of gradient descent, your parameters $(w,b)$ come closer to the optimal values that will achieve the lowest cost $J(w,b)$.\\n\",\n",
    "    \"  \\n\",\n",
    "    \"\\n\",\n",
    "    \"- The trained linear regression model can then take the input feature $x$ (city population) and output a prediction $f_{w,b}(x)$ (predicted monthly profit for a restaurant in that city).\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"<a name=\\\"5\\\"></a>\\n\",\n",
    "    \"## 5 - Compute Cost\\n\",\n",
    "    \"\\n\",\n",
    "    \"Gradient descent involves repeated steps to adjust the value of your parameter $(w,b)$ to gradually get a smaller and smaller cost $J(w,b)$.\\n\",\n",
    "    \"- At each step of gradient descent, it will be helpful for you to monitor your progress by computing the cost $J(w,b)$ as $(w,b)$ gets updated. \\n\",\n",
    "    \"- In this section, you will implement a function to calculate $J(w,b)$ so that you can check the progress of your gradient descent implementation.\\n\",\n",
    "    \"\\n\",\n",
    "    \"#### Cost function\\n\",\n",
    "    \"As you may recall from the lecture, for one variable, the cost function for linear regression $J(w,b)$ is defined as\\n\",\n",
    "    \"\\n\",\n",
    "    \"$$J(w,b) = \\\\frac{1}{2m} \\\\sum\\\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2$$ \\n\",\n",
    "    \"\\n\",\n",
    "    \"- You can think of $f_{w,b}(x^{(i)})$ as the model's prediction of your restaurant's profit, as opposed to $y^{(i)}$, which is the actual profit that is recorded in the data.\\n\",\n",
    "    \"- $m$ is the number of training examples in the dataset\\n\",\n",
    "    \"\\n\",\n",
    "    \"#### Model prediction\\n\",\n",
    "    \"\\n\",\n",
    "    \"- For linear regression with one variable, the prediction of the model $f_{w,b}$ for an example $x^{(i)}$ is representented as:\\n\",\n",
    "    \"\\n\",\n",
    "    \"$$ f_{w,b}(x^{(i)}) = wx^{(i)} + b$$\\n\",\n",
    "    \"\\n\",\n",
    "    \"This is the equation for a line, with an intercept $b$ and a slope $w$\\n\",\n",
    "    \"\\n\",\n",
    "    \"#### Implementation\\n\",\n",
    "    \"\\n\",\n",
    "    \"Please complete the `compute_cost()` function below to compute the cost $J(w,b)$.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"<a name=\\\"ex01\\\"></a>\\n\",\n",
    "    \"### Exercise 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"Complete the `compute_cost` below to:\\n\",\n",
    "    \"\\n\",\n",
    "    \"* Iterate over the training examples, and for each example, compute:\\n\",\n",
    "    \"    * The prediction of the model for that example \\n\",\n",
    "    \"    $$\\n\",\n",
    "    \"    f_{wb}(x^{(i)}) =  wx^{(i)} + b \\n\",\n",
    "    \"    $$\\n\",\n",
    "    \"   \\n\",\n",
    "    \"    * The cost for that example  $$cost^{(i)} =  (f_{wb} - y^{(i)})^2$$\\n\",\n",
    "    \"    \\n\",\n",
    "    \"\\n\",\n",
    "    \"* Return the total cost over all examples\\n\",\n",
    "    \"$$J(\\\\mathbf{w},b) = \\\\frac{1}{2m} \\\\sum\\\\limits_{i = 0}^{m-1} cost^{(i)}$$\\n\",\n",
    "    \"  * Here, $m$ is the number of training examples and $\\\\sum$ is the summation operator\\n\",\n",
    "    \"\\n\",\n",
    "    \"If you get stuck, you can check out the hints presented after the cell below to help you with the implementation.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 9,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# UNQ_C1\\n\",\n",
    "    \"# GRADED FUNCTION: compute_cost\\n\",\n",
    "    \"\\n\",\n",
    "    \"def compute_cost(x, y, w, b): \\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Computes the cost function for linear regression.\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        x (ndarray): Shape (m,) Input to the model (Population of cities) \\n\",\n",
    "    \"        y (ndarray): Shape (m,) Label (Actual profits for the cities)\\n\",\n",
    "    \"        w, b (scalar): Parameters of the model\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Returns\\n\",\n",
    "    \"        total_cost (float): The cost of using w,b as the parameters for linear regression\\n\",\n",
    "    \"               to fit the data points in x and y\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # number of training examples\\n\",\n",
    "    \"    m = x.shape[0] \\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # You need to return this variable correctly\\n\",\n",
    "    \"    total_cost = 0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    ### START CODE HERE ###  \\n\",\n",
    "    \"\\n\",\n",
    "    \"    ### END CODE HERE ### \\n\",\n",
    "    \"\\n\",\n",
    "    \"    return total_cost\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"<details>\\n\",\n",
    "    \"  <summary><font size=\\\"3\\\" color=\\\"darkgreen\\\"><b>Click for hints</b></font></summary>\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    \\n\",\n",
    "    \"   * You can represent a summation operator eg: $h = \\\\sum\\\\limits_{i = 0}^{m-1} 2i$ in code as follows:\\n\",\n",
    "    \"     ```python \\n\",\n",
    "    \"    h = 0\\n\",\n",
    "    \"    for i in range(m):\\n\",\n",
    "    \"        h = h + 2*i\\n\",\n",
    "    \"    ```\\n\",\n",
    "    \"  \\n\",\n",
    "    \"   * In this case, you can iterate over all the examples in `x` using a for loop and add the `cost` from each iteration to a variable (`cost_sum`) initialized outside the loop.\\n\",\n",
    "    \"\\n\",\n",
    "    \"   * Then, you can return the `total_cost` as `cost_sum` divided by `2m`.\\n\",\n",
    "    \"     \\n\",\n",
    "    \"    <details>\\n\",\n",
    "    \"          <summary><font size=\\\"2\\\" color=\\\"darkblue\\\"><b> Click for more hints</b></font></summary>\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    * Here's how you can structure the overall implementation for this function\\n\",\n",
    "    \"    ```python \\n\",\n",
    "    \"    def compute_cost(x, y, w, b):\\n\",\n",
    "    \"        # number of training examples\\n\",\n",
    "    \"        m = x.shape[0] \\n\",\n",
    "    \"    \\n\",\n",
    "    \"        # You need to return this variable correctly\\n\",\n",
    "    \"        total_cost = 0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"        ### START CODE HERE ###  \\n\",\n",
    "    \"        # Variable to keep track of sum of cost from each example\\n\",\n",
    "    \"        cost_sum = 0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"        # Loop over training examples\\n\",\n",
    "    \"        for i in range(m):\\n\",\n",
    "    \"            # Your code here to get the prediction f_wb for the ith example\\n\",\n",
    "    \"            f_wb = \\n\",\n",
    "    \"            # Your code here to get the cost associated with the ith example\\n\",\n",
    "    \"            cost = \\n\",\n",
    "    \"        \\n\",\n",
    "    \"            # Add to sum of cost for each example\\n\",\n",
    "    \"            cost_sum = cost_sum + cost \\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Get the total cost as the sum divided by (2*m)\\n\",\n",
    "    \"        total_cost = (1 / (2 * m)) * cost_sum\\n\",\n",
    "    \"        ### END CODE HERE ### \\n\",\n",
    "    \"\\n\",\n",
    "    \"        return total_cost\\n\",\n",
    "    \"    ```\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    If you're still stuck, you can check the hints presented below to figure out how to calculate `f_wb` and `cost`.\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    <details>\\n\",\n",
    "    \"          <summary><font size=\\\"2\\\" color=\\\"darkblue\\\"><b>Hint to calculate f_wb</b></font></summary>\\n\",\n",
    "    \"           &emsp; &emsp; For scalars $a$, $b$ and $c$ (<code>x[i]</code>, <code>w</code> and <code>b</code> are all scalars), you can calculate the equation $h = ab + c$ in code as <code>h = a * b + c</code>\\n\",\n",
    "    \"          <details>\\n\",\n",
    "    \"              <summary><font size=\\\"2\\\" color=\\\"blue\\\"><b>&emsp; &emsp; More hints to calculate f</b></font></summary>\\n\",\n",
    "    \"               &emsp; &emsp; You can compute f_wb as <code>f_wb = w * x[i] + b </code>\\n\",\n",
    "    \"           </details>\\n\",\n",
    "    \"    </details>\\n\",\n",
    "    \"\\n\",\n",
    "    \"     <details>\\n\",\n",
    "    \"          <summary><font size=\\\"2\\\" color=\\\"darkblue\\\"><b>Hint to calculate cost</b></font></summary>\\n\",\n",
    "    \"          &emsp; &emsp; You can calculate the square of a variable z as z**2\\n\",\n",
    "    \"          <details>\\n\",\n",
    "    \"              <summary><font size=\\\"2\\\" color=\\\"blue\\\"><b>&emsp; &emsp; More hints to calculate cost</b></font></summary>\\n\",\n",
    "    \"              &emsp; &emsp; You can compute cost as <code>cost = (f_wb - y[i]) ** 2</code>\\n\",\n",
    "    \"          </details>\\n\",\n",
    "    \"    </details>\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    </details>\\n\",\n",
    "    \"\\n\",\n",
    "    \"</details>\\n\",\n",
    "    \"\\n\",\n",
    "    \"    \\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"You can check if your implementation was correct by running the following test code:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 10,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"<class 'numpy.float64'>\\n\",\n",
    "      \"Cost at initial w (zeros): 75.203\\n\",\n",
    "      \"\\u001b[92mAll tests passed!\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"# Compute cost with some initial values for paramaters w, b\\n\",\n",
    "    \"initial_w = 2\\n\",\n",
    "    \"initial_b = 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"cost = compute_cost(x_train, y_train, initial_w, initial_b)\\n\",\n",
    "    \"print(type(cost))\\n\",\n",
    "    \"print(f'Cost at initial w (zeros): {cost:.3f}')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Public tests\\n\",\n",
    "    \"from public_tests import *\\n\",\n",
    "    \"compute_cost_test(compute_cost)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"**Expected Output**:\\n\",\n",
    "    \"<table>\\n\",\n",
    "    \"  <tr>\\n\",\n",
    "    \"    <td> <b>Cost at initial w (zeros):<b> 75.203 </td> \\n\",\n",
    "    \"  </tr>\\n\",\n",
    "    \"</table>\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"<a name=\\\"6\\\"></a>\\n\",\n",
    "    \"## 6 - Gradient descent \\n\",\n",
    "    \"\\n\",\n",
    "    \"In this section, you will implement the gradient for parameters $w, b$ for linear regression. \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"As described in the lecture videos, the gradient descent algorithm is:\\n\",\n",
    "    \"\\n\",\n",
    "    \"$$\\\\begin{align*}& \\\\text{repeat until convergence:} \\\\; \\\\lbrace \\\\newline \\\\; & \\\\phantom {0000} b := b -  \\\\alpha \\\\frac{\\\\partial J(w,b)}{\\\\partial b} \\\\newline       \\\\; & \\\\phantom {0000} w := w -  \\\\alpha \\\\frac{\\\\partial J(w,b)}{\\\\partial w} \\\\tag{1}  \\\\; & \\n\",\n",
    "    \"\\\\newline & \\\\rbrace\\\\end{align*}$$\\n\",\n",
    "    \"\\n\",\n",
    "    \"where, parameters $w, b$ are both updated simultaniously and where  \\n\",\n",
    "    \"$$\\n\",\n",
    "    \"\\\\frac{\\\\partial J(w,b)}{\\\\partial b}  = \\\\frac{1}{m} \\\\sum\\\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\\\tag{2}\\n\",\n",
    "    \"$$\\n\",\n",
    "    \"$$\\n\",\n",
    "    \"\\\\frac{\\\\partial J(w,b)}{\\\\partial w}  = \\\\frac{1}{m} \\\\sum\\\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) -y^{(i)})x^{(i)} \\\\tag{3}\\n\",\n",
    "    \"$$\\n\",\n",
    "    \"* m is the number of training examples in the dataset\\n\",\n",
    "    \"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"*  $f_{w,b}(x^{(i)})$ is the model's prediction, while $y^{(i)}$, is the target value\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"You will implement a function called `compute_gradient` which calculates $\\\\frac{\\\\partial J(w)}{\\\\partial w}$, $\\\\frac{\\\\partial J(w)}{\\\\partial b}$ \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"<a name=\\\"ex02\\\"></a>\\n\",\n",
    "    \"### Exercise 2\\n\",\n",
    "    \"\\n\",\n",
    "    \"Please complete the `compute_gradient` function to:\\n\",\n",
    "    \"\\n\",\n",
    "    \"* Iterate over the training examples, and for each example, compute:\\n\",\n",
    "    \"    * The prediction of the model for that example \\n\",\n",
    "    \"    $$\\n\",\n",
    "    \"    f_{wb}(x^{(i)}) =  wx^{(i)} + b \\n\",\n",
    "    \"    $$\\n\",\n",
    "    \"   \\n\",\n",
    "    \"    * The gradient for the parameters $w, b$ from that example \\n\",\n",
    "    \"        $$\\n\",\n",
    "    \"        \\\\frac{\\\\partial J(w,b)}{\\\\partial b}^{(i)}  =  (f_{w,b}(x^{(i)}) - y^{(i)}) \\n\",\n",
    "    \"        $$\\n\",\n",
    "    \"        $$\\n\",\n",
    "    \"        \\\\frac{\\\\partial J(w,b)}{\\\\partial w}^{(i)}  =  (f_{w,b}(x^{(i)}) -y^{(i)})x^{(i)} \\n\",\n",
    "    \"        $$\\n\",\n",
    "    \"    \\n\",\n",
    "    \"\\n\",\n",
    "    \"* Return the total gradient update from all the examples\\n\",\n",
    "    \"    $$\\n\",\n",
    "    \"    \\\\frac{\\\\partial J(w,b)}{\\\\partial b}  = \\\\frac{1}{m} \\\\sum\\\\limits_{i = 0}^{m-1} \\\\frac{\\\\partial J(w,b)}{\\\\partial b}^{(i)}\\n\",\n",
    "    \"    $$\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    $$\\n\",\n",
    "    \"    \\\\frac{\\\\partial J(w,b)}{\\\\partial w}  = \\\\frac{1}{m} \\\\sum\\\\limits_{i = 0}^{m-1} \\\\frac{\\\\partial J(w,b)}{\\\\partial w}^{(i)} \\n\",\n",
    "    \"    $$\\n\",\n",
    "    \"  * Here, $m$ is the number of training examples and $\\\\sum$ is the summation operator\\n\",\n",
    "    \"\\n\",\n",
    "    \"If you get stuck, you can check out the hints presented after the cell below to help you with the implementation.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# UNQ_C2\\n\",\n",
    "    \"# GRADED FUNCTION: compute_gradient\\n\",\n",
    "    \"def compute_gradient(x, y, w, b): \\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Computes the gradient for linear regression \\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"      x (ndarray): Shape (m,) Input to the model (Population of cities) \\n\",\n",
    "    \"      y (ndarray): Shape (m,) Label (Actual profits for the cities)\\n\",\n",
    "    \"      w, b (scalar): Parameters of the model  \\n\",\n",
    "    \"    Returns\\n\",\n",
    "    \"      dj_dw (scalar): The gradient of the cost w.r.t. the parameters w\\n\",\n",
    "    \"      dj_db (scalar): The gradient of the cost w.r.t. the parameter b     \\n\",\n",
    "    \"     \\\"\\\"\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Number of training examples\\n\",\n",
    "    \"    m = x.shape[0]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # You need to return the following variables correctly\\n\",\n",
    "    \"    dj_dw = 0\\n\",\n",
    "    \"    dj_db = 0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    ### START CODE HERE ### \\n\",\n",
    "    \"    \\n\",\n",
    "    \"    ### END CODE HERE ### \\n\",\n",
    "    \"        \\n\",\n",
    "    \"    return dj_dw, dj_db\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"<details>\\n\",\n",
    "    \"  <summary><font size=\\\"3\\\" color=\\\"darkgreen\\\"><b>Click for hints</b></font></summary>\\n\",\n",
    "    \"       \\n\",\n",
    "    \"    * You can represent a summation operator eg: $h = \\\\sum\\\\limits_{i = 0}^{m-1} 2i$ in code as follows:\\n\",\n",
    "    \"     ```python \\n\",\n",
    "    \"    h = 0\\n\",\n",
    "    \"    for i in range(m):\\n\",\n",
    "    \"        h = h + 2*i\\n\",\n",
    "    \"    ```\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    * In this case, you can iterate over all the examples in `x` using a for loop and for each example, keep adding the gradient from that example to the variables `dj_dw` and `dj_db` which are initialized outside the loop. \\n\",\n",
    "    \"\\n\",\n",
    "    \"   * Then, you can return `dj_dw` and `dj_db` both divided by `m`.    \\n\",\n",
    "    \"    <details>\\n\",\n",
    "    \"          <summary><font size=\\\"2\\\" color=\\\"darkblue\\\"><b> Click for more hints</b></font></summary>\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    * Here's how you can structure the overall implementation for this function\\n\",\n",
    "    \"    ```python \\n\",\n",
    "    \"    def compute_gradient(x, y, w, b): \\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        Computes the gradient for linear regression \\n\",\n",
    "    \"        Args:\\n\",\n",
    "    \"          x (ndarray): Shape (m,) Input to the model (Population of cities) \\n\",\n",
    "    \"          y (ndarray): Shape (m,) Label (Actual profits for the cities)\\n\",\n",
    "    \"          w, b (scalar): Parameters of the model  \\n\",\n",
    "    \"        Returns\\n\",\n",
    "    \"          dj_dw (scalar): The gradient of the cost w.r.t. the parameters w\\n\",\n",
    "    \"          dj_db (scalar): The gradient of the cost w.r.t. the parameter b     \\n\",\n",
    "    \"         \\\"\\\"\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"        # Number of training examples\\n\",\n",
    "    \"        m = x.shape[0]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"        # You need to return the following variables correctly\\n\",\n",
    "    \"        dj_dw = 0\\n\",\n",
    "    \"        dj_db = 0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"        ### START CODE HERE ### \\n\",\n",
    "    \"        # Loop over examples\\n\",\n",
    "    \"        for i in range(m):  \\n\",\n",
    "    \"            # Your code here to get prediction f_wb for the ith example\\n\",\n",
    "    \"            f_wb = \\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Your code here to get the gradient for w from the ith example \\n\",\n",
    "    \"            dj_dw_i = \\n\",\n",
    "    \"        \\n\",\n",
    "    \"            # Your code here to get the gradient for b from the ith example \\n\",\n",
    "    \"            dj_db_i = \\n\",\n",
    "    \"     \\n\",\n",
    "    \"            # Update dj_db : In Python, a += 1  is the same as a = a + 1\\n\",\n",
    "    \"            dj_db += dj_db_i\\n\",\n",
    "    \"        \\n\",\n",
    "    \"            # Update dj_dw\\n\",\n",
    "    \"            dj_dw += dj_dw_i\\n\",\n",
    "    \"    \\n\",\n",
    "    \"        # Divide both dj_dw and dj_db by m\\n\",\n",
    "    \"        dj_dw = dj_dw / m\\n\",\n",
    "    \"        dj_db = dj_db / m\\n\",\n",
    "    \"        ### END CODE HERE ### \\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return dj_dw, dj_db\\n\",\n",
    "    \"    ```\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    If you're still stuck, you can check the hints presented below to figure out how to calculate `f_wb` and `cost`.\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    <details>\\n\",\n",
    "    \"          <summary><font size=\\\"2\\\" color=\\\"darkblue\\\"><b>Hint to calculate f_wb</b></font></summary>\\n\",\n",
    "    \"           &emsp; &emsp; You did this in the previous exercise! For scalars $a$, $b$ and $c$ (<code>x[i]</code>, <code>w</code> and <code>b</code> are all scalars), you can calculate the equation $h = ab + c$ in code as <code>h = a * b + c</code>\\n\",\n",
    "    \"          <details>\\n\",\n",
    "    \"              <summary><font size=\\\"2\\\" color=\\\"blue\\\"><b>&emsp; &emsp; More hints to calculate f</b></font></summary>\\n\",\n",
    "    \"               &emsp; &emsp; You can compute f_wb as <code>f_wb = w * x[i] + b </code>\\n\",\n",
    "    \"           </details>\\n\",\n",
    "    \"    </details>\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    <details>\\n\",\n",
    "    \"          <summary><font size=\\\"2\\\" color=\\\"darkblue\\\"><b>Hint to calculate dj_dw_i</b></font></summary>\\n\",\n",
    "    \"           &emsp; &emsp; For scalars $a$, $b$ and $c$ (<code>f_wb</code>, <code>y[i]</code> and <code>x[i]</code> are all scalars), you can calculate the equation $h = (a - b)c$ in code as <code>h = (a-b)*c</code>\\n\",\n",
    "    \"          <details>\\n\",\n",
    "    \"              <summary><font size=\\\"2\\\" color=\\\"blue\\\"><b>&emsp; &emsp; More hints to calculate f</b></font></summary>\\n\",\n",
    "    \"               &emsp; &emsp; You can compute dj_dw_i as <code>dj_dw_i = (f_wb - y[i]) * x[i] </code>\\n\",\n",
    "    \"           </details>\\n\",\n",
    "    \"    </details>\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    <details>\\n\",\n",
    "    \"          <summary><font size=\\\"2\\\" color=\\\"darkblue\\\"><b>Hint to calculate dj_db_i</b></font></summary>\\n\",\n",
    "    \"             &emsp; &emsp; You can compute dj_db_i as <code> dj_db_i = f_wb - y[i] </code>\\n\",\n",
    "    \"    </details>\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    </details>\\n\",\n",
    "    \"\\n\",\n",
    "    \"</details>\\n\",\n",
    "    \"\\n\",\n",
    "    \"    \\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Run the cells below to check your implementation of the `compute_gradient` function with two different initializations of the parameters $w$,$b$.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Compute and display gradient with w initialized to zeroes\\n\",\n",
    "    \"initial_w = 0\\n\",\n",
    "    \"initial_b = 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"tmp_dj_dw, tmp_dj_db = compute_gradient(x_train, y_train, initial_w, initial_b)\\n\",\n",
    "    \"print('Gradient at initial w, b (zeros):', tmp_dj_dw, tmp_dj_db)\\n\",\n",
    "    \"\\n\",\n",
    "    \"compute_gradient_test(compute_gradient)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Now let's run the gradient descent algorithm implemented above on our dataset.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Expected Output**:\\n\",\n",
    "    \"<table>\\n\",\n",
    "    \"  <tr>\\n\",\n",
    "    \"    <td> <b>Gradient at initial , b (zeros)<b></td>\\n\",\n",
    "    \"    <td> -65.32884975 -5.83913505154639</td> \\n\",\n",
    "    \"  </tr>\\n\",\n",
    "    \"</table>\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Compute and display cost and gradient with non-zero w\\n\",\n",
    "    \"test_w = 0.2\\n\",\n",
    "    \"test_b = 0.2\\n\",\n",
    "    \"tmp_dj_dw, tmp_dj_db = compute_gradient(x_train, y_train, test_w, test_b)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('Gradient at test w, b:', tmp_dj_dw, tmp_dj_db)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"**Expected Output**:\\n\",\n",
    "    \"<table>\\n\",\n",
    "    \"  <tr>\\n\",\n",
    "    \"    <td> <b>Gradient at test w<b></td>\\n\",\n",
    "    \"    <td> -47.41610118 -4.007175051546391</td> \\n\",\n",
    "    \"  </tr>\\n\",\n",
    "    \"</table>\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"<a name=\\\"2.6\\\"></a>\\n\",\n",
    "    \"### 2.6 Learning parameters using batch gradient descent \\n\",\n",
    "    \"\\n\",\n",
    "    \"You will now find the optimal parameters of a linear regression model by using batch gradient descent. Recall batch refers to running all the examples in one iteration.\\n\",\n",
    "    \"- You don't need to implement anything for this part. Simply run the cells below. \\n\",\n",
    "    \"\\n\",\n",
    "    \"- A good way to verify that gradient descent is working correctly is to look\\n\",\n",
    "    \"at the value of $J(w,b)$ and check that it is decreasing with each step. \\n\",\n",
    "    \"\\n\",\n",
    "    \"- Assuming you have implemented the gradient and computed the cost correctly and you have an appropriate value for the learning rate alpha, $J(w,b)$ should never increase and should converge to a steady value by the end of the algorithm.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def gradient_descent(x, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Performs batch gradient descent to learn theta. Updates theta by taking \\n\",\n",
    "    \"    num_iters gradient steps with learning rate alpha\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"      x :    (ndarray): Shape (m,)\\n\",\n",
    "    \"      y :    (ndarray): Shape (m,)\\n\",\n",
    "    \"      w_in, b_in : (scalar) Initial values of parameters of the model\\n\",\n",
    "    \"      cost_function: function to compute cost\\n\",\n",
    "    \"      gradient_function: function to compute the gradient\\n\",\n",
    "    \"      alpha : (float) Learning rate\\n\",\n",
    "    \"      num_iters : (int) number of iterations to run gradient descent\\n\",\n",
    "    \"    Returns\\n\",\n",
    "    \"      w : (ndarray): Shape (1,) Updated values of parameters of the model after\\n\",\n",
    "    \"          running gradient descent\\n\",\n",
    "    \"      b : (scalar)                Updated value of parameter of the model after\\n\",\n",
    "    \"          running gradient descent\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # number of training examples\\n\",\n",
    "    \"    m = len(x)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # An array to store cost J and w's at each iteration  primarily for graphing later\\n\",\n",
    "    \"    J_history = []\\n\",\n",
    "    \"    w_history = []\\n\",\n",
    "    \"    w = copy.deepcopy(w_in)  #avoid modifying global w within function\\n\",\n",
    "    \"    b = b_in\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i in range(num_iters):\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Calculate the gradient and update the parameters\\n\",\n",
    "    \"        dj_dw, dj_db = gradient_function(x, y, w, b )  \\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Update Parameters using w, b, alpha and gradient\\n\",\n",
    "    \"        w = w - alpha * dj_dw               \\n\",\n",
    "    \"        b = b - alpha * dj_db               \\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Save cost J at each iteration\\n\",\n",
    "    \"        if i<100000:      # prevent resource exhaustion \\n\",\n",
    "    \"            cost =  cost_function(x, y, w, b)\\n\",\n",
    "    \"            J_history.append(cost)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Print cost every at intervals 10 times or as many iterations if < 10\\n\",\n",
    "    \"        if i% math.ceil(num_iters/10) == 0:\\n\",\n",
    "    \"            w_history.append(w)\\n\",\n",
    "    \"            print(f\\\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}   \\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    return w, b, J_history, w_history #return w and J,w history for graphing\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Now let's run the gradient descent algorithm above to learn the parameters for our dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# initialize fitting parameters. Recall that the shape of w is (n,)\\n\",\n",
    "    \"initial_w = 0.\\n\",\n",
    "    \"initial_b = 0.\\n\",\n",
    "    \"\\n\",\n",
    "    \"# some gradient descent settings\\n\",\n",
    "    \"iterations = 1500\\n\",\n",
    "    \"alpha = 0.01\\n\",\n",
    "    \"\\n\",\n",
    "    \"w,b,_,_ = gradient_descent(x_train ,y_train, initial_w, initial_b, \\n\",\n",
    "    \"                     compute_cost, compute_gradient, alpha, iterations)\\n\",\n",
    "    \"print(\\\"w,b found by gradient descent:\\\", w, b)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"**Expected Output**:\\n\",\n",
    "    \"<table>\\n\",\n",
    "    \"  <tr>\\n\",\n",
    "    \"    <td> <b> w, b found by gradient descent<b></td>\\n\",\n",
    "    \"    <td> 1.16636235 -3.63029143940436</td> \\n\",\n",
    "    \"  </tr>\\n\",\n",
    "    \"</table>\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"We will now use the final parameters from gradient descent to plot the linear fit. \\n\",\n",
    "    \"\\n\",\n",
    "    \"Recall that we can get the prediction for a single example $f(x^{(i)})= wx^{(i)}+b$. \\n\",\n",
    "    \"\\n\",\n",
    "    \"To calculate the predictions on the entire dataset, we can loop through all the training examples and calculate the prediction for each example. This is shown in the code block below.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"m = x_train.shape[0]\\n\",\n",
    "    \"predicted = np.zeros(m)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i in range(m):\\n\",\n",
    "    \"    predicted[i] = w * x_train[i] + b\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"We will now plot the predicted values to see the linear fit.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot the linear fit\\n\",\n",
    "    \"plt.plot(x_train, predicted, c = \\\"b\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create a scatter plot of the data. \\n\",\n",
    "    \"plt.scatter(x_train, y_train, marker='x', c='r') \\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set the title\\n\",\n",
    "    \"plt.title(\\\"Profits vs. Population per city\\\")\\n\",\n",
    "    \"# Set the y-axis label\\n\",\n",
    "    \"plt.ylabel('Profit in $10,000')\\n\",\n",
    "    \"# Set the x-axis label\\n\",\n",
    "    \"plt.xlabel('Population of City in 10,000s')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Your final values of $w,b$ can also be used to make predictions on profits. Let's predict what the profit would be in areas of 35,000 and 70,000 people. \\n\",\n",
    "    \"\\n\",\n",
    "    \"- The model takes in population of a city in 10,000s as input. \\n\",\n",
    "    \"\\n\",\n",
    "    \"- Therefore, 35,000 people can be translated into an input to the model as `np.array([3.5])`\\n\",\n",
    "    \"\\n\",\n",
    "    \"- Similarly, 70,000 people can be translated into an input to the model as `np.array([7.])`\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"predict1 = 3.5 * w + b\\n\",\n",
    "    \"print('For population = 35,000, we predict a profit of $%.2f' % (predict1*10000))\\n\",\n",
    "    \"\\n\",\n",
    "    \"predict2 = 7.0 * w + b\\n\",\n",
    "    \"print('For population = 70,000, we predict a profit of $%.2f' % (predict2*10000))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"**Expected Output**:\\n\",\n",
    "    \"<table>\\n\",\n",
    "    \"  <tr>\\n\",\n",
    "    \"    <td> <b> For population = 35,000, we predict a profit of<b></td>\\n\",\n",
    "    \"    <td> $4519.77 </td> \\n\",\n",
    "    \"  </tr>\\n\",\n",
    "    \"  \\n\",\n",
    "    \"  <tr>\\n\",\n",
    "    \"    <td> <b> For population = 70,000, we predict a profit of<b></td>\\n\",\n",
    "    \"    <td> $45342.45 </td> \\n\",\n",
    "    \"  </tr>\\n\",\n",
    "    \"</table>\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
